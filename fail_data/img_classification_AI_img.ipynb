{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import dlib\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "datFile =  'C:/Users/jungh/final_project/landmarks/shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "# Dlib의 얼굴 인식기 초기화\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(datFile)\n",
    "faces = detector(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'C:/Users/jungh/final_project/img_path' \n",
    "cool_path = 'C:/Users/jungh/final_project/classified_img/cool'\n",
    "warm_path = 'C:/Users/jungh/final_project/classified_img/warm'\n",
    "file_list = os.listdir(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿨톤과 웜톤 수 초기화\n",
    "cool_count = 0\n",
    "warm_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장한사진 웜쿨 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'C:/Users/jungh/final_project/img_path' \n",
    "file_list = os.listdir(img_path)\n",
    "for file in tqdm(file_list, desc=\"Processing images\"):\n",
    "    # 이미지 파일 경로\n",
    "    image_path = os.path.join(img_path, file)\n",
    "    \n",
    "    # 이미지 로드\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # 피부 톤 추출 및 배경 처리\n",
    "    img_HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17, 170, 255))\n",
    "    HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "    \n",
    "    img_YCrCb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255, 180, 135))\n",
    "    YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "    \n",
    "    global_mask = cv2.bitwise_and(YCrCb_mask, HSV_mask)\n",
    "    global_mask = cv2.medianBlur(global_mask, 3)\n",
    "    global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4, 4), np.uint8))\n",
    "    \n",
    "    global_result = cv2.bitwise_not(global_mask)\n",
    "    global_result_color = cv2.bitwise_not(global_result)\n",
    "    \n",
    "    output_image = cv2.bitwise_and(image, image, mask=global_result_color)\n",
    "    output_image[global_result_color == 0] = (255, 255, 255)\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    hue = hsv_image[:, :, 0]\n",
    "    \n",
    "    lab_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2LAB)\n",
    "    L, a, b = lab_image[:, :, 0], lab_image[:, :, 1], lab_image[:, :, 2]\n",
    "    \n",
    "    if np.mean(a)*1.018 > np.mean(b):\n",
    "        cool_count += 1\n",
    "        copyfile(image_path, os.path.join(cool_path, file))\n",
    "    else:\n",
    "        warm_count += 1\n",
    "        copyfile(image_path, os.path.join(warm_path, file))\n",
    "    \n",
    "# 결과 출력\n",
    "print(\"쿨톤 수:\", cool_count)\n",
    "print(\"웜톤 수:\", warm_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.02 곱한 경우 쿨톤 수: 8491 웜톤 수: 4708\n",
    "\n",
    "1.018 곱한 경우 쿨톤 수: 6647 웜톤 수: 6552"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웜쿨 분류한 사진 봄여름가을겨울 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머리카락만 남기고 나머지 배경을 하얀색으로 만들어주는 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hair의 lab의 L 과 skin의 lab의 L의 차이에 따라 각각의 계절로 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# warm에서 spring와 fall 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'C:/Users/jungh/final_project/classified_img/warm' \n",
    "spring_path = 'C:/Users/jungh/final_project/classified_img/warm/spring'\n",
    "fall_path = 'C:/Users/jungh/final_project/classified_img/warm/fall'\n",
    "\n",
    "file_list = os.listdir(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring = 0\n",
    "fall = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(file_list, desc=\"Processing images\"):\n",
    "  image_path = os.path.join(img_path, file)\n",
    "    \n",
    "    # 이미지 로드\n",
    "  image = cv2.imread(image_path)\n",
    "  \n",
    "  img_HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "  HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17, 170, 255))\n",
    "  HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "\n",
    "  img_YCrCb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "  YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255, 180, 135))\n",
    "  YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "\n",
    "  global_mask = cv2.bitwise_and(YCrCb_mask, HSV_mask)\n",
    "  global_mask = cv2.medianBlur(global_mask, 3)\n",
    "  global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4, 4), np.uint8))\n",
    "\n",
    "  global_result = cv2.bitwise_not(global_mask)\n",
    "  global_result_color = cv2.bitwise_not(global_result)\n",
    "\n",
    "  skin_output = cv2.bitwise_and(image, image, mask=global_result_color)\n",
    "\n",
    "  # 헤어\n",
    "  spatial_radius = 10\n",
    "  color_radius = 10\n",
    "  max_pyramid_level = 1\n",
    "\n",
    "  # Mean Shift 세그멘테이션을 수행합니다.\n",
    "  segmented = cv2.pyrMeanShiftFiltering(image, spatial_radius, color_radius, maxLevel=max_pyramid_level)\n",
    "\n",
    "  # 세그멘테이션된 이미지를 그레이스케일로 변환합니다.\n",
    "  segmented_gray = cv2.cvtColor(segmented, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # 이진화를 수행하여 머리카락 영역을 추출합니다.\n",
    "  _, hair_mask = cv2.threshold(segmented_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "  # 목 주변의 영역을 더욱 정확하게 제거하기 위해 모폴로지 연산을 적용합니다.\n",
    "  kernel = np.ones((5, 5), np.uint8)\n",
    "  hair_mask = cv2.morphologyEx(hair_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "  # 머리카락 영역을 원본 이미지에 적용하여 머리카락만 남기고 나머지는 흰색으로 처리합니다.\n",
    "  hair_output = cv2.bitwise_and(image, image, mask=hair_mask)\n",
    "  \n",
    "  skin_lab = cv2.cvtColor(skin_output, cv2.COLOR_BGR2LAB)\n",
    "  skin_brightness = np.mean(skin_lab[:, :, 0]) \n",
    "\n",
    "  hair_lab = cv2.cvtColor(hair_output, cv2.COLOR_BGR2LAB)\n",
    "  hair_brightness = np.mean(hair_lab[:, :, 0])\n",
    "\n",
    "  contrast = skin_brightness - hair_brightness\n",
    "\n",
    "  if contrast < 50:\n",
    "    fall += 1\n",
    "    copyfile(image_path, os.path.join(fall_path, file))\n",
    "\n",
    "  else:\n",
    "    spring += 1\n",
    "    copyfile(image_path, os.path.join(spring_path, file))\n",
    "\n",
    "    \n",
    "print(spring)\n",
    "print(fall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cool에서 summer와 winter 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'C:/Users/jungh/final_project/classified_img/cool' \n",
    "summer_path = 'C:/Users/jungh/final_project/classified_img/cool/summer'\n",
    "winter_path = 'C:/Users/jungh/final_project/classified_img/cool/winter'\n",
    "\n",
    "file_list = os.listdir(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer = 0\n",
    "winter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(file_list, desc=\"Processing images\"):\n",
    "  image_path = os.path.join(img_path, file)\n",
    "    \n",
    "    # 이미지 로드\n",
    "  image = cv2.imread(image_path)\n",
    "  \n",
    "  img_HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "  HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17, 170, 255))\n",
    "  HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "\n",
    "  img_YCrCb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "  YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255, 180, 135))\n",
    "  YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8))\n",
    "\n",
    "  global_mask = cv2.bitwise_and(YCrCb_mask, HSV_mask)\n",
    "  global_mask = cv2.medianBlur(global_mask, 3)\n",
    "  global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4, 4), np.uint8))\n",
    "\n",
    "  global_result = cv2.bitwise_not(global_mask)\n",
    "  global_result_color = cv2.bitwise_not(global_result)\n",
    "\n",
    "  skin_output = cv2.bitwise_and(image, image, mask=global_result_color)\n",
    "\n",
    "  # 헤어\n",
    "  spatial_radius = 10\n",
    "  color_radius = 10\n",
    "  max_pyramid_level = 1\n",
    "\n",
    "  # Mean Shift 세그멘테이션을 수행합니다.\n",
    "  segmented = cv2.pyrMeanShiftFiltering(image, spatial_radius, color_radius, maxLevel=max_pyramid_level)\n",
    "\n",
    "  # 세그멘테이션된 이미지를 그레이스케일로 변환합니다.\n",
    "  segmented_gray = cv2.cvtColor(segmented, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  # 이진화를 수행하여 머리카락 영역을 추출합니다.\n",
    "  _, hair_mask = cv2.threshold(segmented_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "  # 목 주변의 영역을 더욱 정확하게 제거하기 위해 모폴로지 연산을 적용합니다.\n",
    "  kernel = np.ones((5, 5), np.uint8)\n",
    "  hair_mask = cv2.morphologyEx(hair_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "  # 머리카락 영역을 원본 이미지에 적용하여 머리카락만 남기고 나머지는 흰색으로 처리합니다.\n",
    "  hair_output = cv2.bitwise_and(image, image, mask=hair_mask)\n",
    "  \n",
    "  skin_lab = cv2.cvtColor(skin_output, cv2.COLOR_BGR2LAB)\n",
    "  skin_brightness = np.mean(skin_lab[:, :, 0]) \n",
    "\n",
    "  hair_lab = cv2.cvtColor(hair_output, cv2.COLOR_BGR2LAB)\n",
    "  hair_brightness = np.mean(hair_lab[:, :, 0])\n",
    "\n",
    "  contrast = skin_brightness - hair_brightness\n",
    "\n",
    "  if contrast < 50:\n",
    "    summer += 1\n",
    "    copyfile(image_path, os.path.join(summer_path, file))\n",
    "\n",
    "  else:\n",
    "    winter += 1\n",
    "    copyfile(image_path, os.path.join(winter_path, file))\n",
    "\n",
    "    \n",
    "print(summer)\n",
    "print(winter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
