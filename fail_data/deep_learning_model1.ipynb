{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 눈 이미지를 사용해서 봄여름가을겨울을 나누는 딥러닝 시작."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision torchaudio\n",
    "# pip install efficientnet_pytorch\n",
    "# pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn import preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = 'C:/Users/jungh/final_project/img_path/eye_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 전처리와 전처리한 데이터를 저장하기 위해 사용\n",
    "# for root, dirs, files in os.walk(base_path): # os.walk()를 사용하면 모든 하위 폴더와 파일을 탐색 할 수 있다  하위의 폴더들을 for문으로 탐색할 수 있게 해줌\n",
    "#     for file in files:\n",
    "#         if file.lower().endswith('.jpg') or file.lower().endswith('.jpeg'):\n",
    "#             image_path = os.path.join(root, file)\n",
    "\n",
    "#             # 이미지 변환 코드\n",
    "#             eye = cv2.imread(image_path)\n",
    "#             eye_gray = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)\n",
    "#             _, thresholded = cv2.threshold(eye_gray, 90, 255, cv2.THRESH_BINARY)\n",
    "#             thresholded = cv2.inRange(thresholded, 0, 1)\n",
    "#             eye_masked = cv2.bitwise_and(eye, eye, mask=thresholded)\n",
    "\n",
    "#             # 이미지 저장 코드\n",
    "#             output_dir = os.path.join(root, 'processed')\n",
    "#             os.makedirs(output_dir, exist_ok=True)\n",
    "#             output_path = os.path.join(output_dir, file)\n",
    "#             cv2.imwrite(output_path, eye_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "learning_rate = 0.0001\n",
    "batch_size = 20\n",
    "num_epochs = 30\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로\n",
    "data_path = 'C:/Users/jungh/final_project/eye_deeplearning'\n",
    "classes = ['spring', 'summer', 'fall', 'winter']\n",
    "num_classes = len(classes)\n",
    "image_size = (64, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, images, labels):\n",
    "    self.images = images\n",
    "    self.labels = labels\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    image = self.images[idx]\n",
    "    label = self.labels[idx]\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc1 = nn.Linear(32 * (image_size[0] // 2) * (image_size[1] // 2), 64)\n",
    "    self.fc2 = nn.Linear(64, num_classes)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "  x = []\n",
    "  y = []\n",
    "  \n",
    "  for i, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(data_path, class_name)\n",
    "    for image_name in os.listdir(class_path):\n",
    "      image_path = os.path.join(class_path, image_name)\n",
    "      image = cv2.imread(image_path)\n",
    "      image = cv2.resize(image, image_size)\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      x.append(image)\n",
    "      y.append(i)\n",
    "  \n",
    "  x = np.array(x)\n",
    "  y = np.array(y)\n",
    "  \n",
    "  return x, y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용\n",
    "def load_dataset():\n",
    "  x = []\n",
    "  y = []\n",
    "  \n",
    "  for i, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(data_path, class_name)\n",
    "    for image_name in os.listdir(class_path):\n",
    "      image_path = os.path.join(class_path, image_name)\n",
    "      image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "      image = cv2.resize(image, image_size)\n",
    "      x.append(image)\n",
    "      y.append(i)\n",
    "  \n",
    "  x = np.array(x)\n",
    "  y = np.array(y)\n",
    "  \n",
    "  return x, y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_dataset()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=SEED)\n",
    "\n",
    "x_train = x_train.reshape(-1, 3, image_size[0], image_size[1])\n",
    "x_test = x_test.reshape(-1, 3, image_size[0], image_size[1])\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MyModel().float().to(device)\n",
    "model.conv1 = nn.Conv2d(x.shape[3], 32, kernel_size=3, stride=1, padding=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 63/63 [00:06<00:00, 10.31batch/s, loss=4.6] \n",
      "Epoch 2/30: 100%|██████████| 63/63 [00:07<00:00,  8.71batch/s, loss=1.61] \n",
      "Epoch 3/30: 100%|██████████| 63/63 [00:08<00:00,  7.10batch/s, loss=1.37] \n",
      "Epoch 4/30: 100%|██████████| 63/63 [00:11<00:00,  5.66batch/s, loss=1.28] \n",
      "Epoch 5/30: 100%|██████████| 63/63 [00:08<00:00,  7.03batch/s, loss=1.16] \n",
      "Epoch 6/30: 100%|██████████| 63/63 [00:06<00:00,  9.53batch/s, loss=1.02] \n",
      "Epoch 7/30: 100%|██████████| 63/63 [00:05<00:00, 10.92batch/s, loss=1.08] \n",
      "Epoch 8/30: 100%|██████████| 63/63 [00:05<00:00, 10.96batch/s, loss=0.966]\n",
      "Epoch 9/30: 100%|██████████| 63/63 [00:05<00:00, 11.01batch/s, loss=1.06] \n",
      "Epoch 10/30: 100%|██████████| 63/63 [00:05<00:00, 11.09batch/s, loss=0.77] \n",
      "Epoch 11/30: 100%|██████████| 63/63 [00:05<00:00, 11.27batch/s, loss=0.709] \n",
      "Epoch 12/30: 100%|██████████| 63/63 [00:08<00:00,  7.41batch/s, loss=0.729]\n",
      "Epoch 13/30: 100%|██████████| 63/63 [00:07<00:00,  7.96batch/s, loss=0.693] \n",
      "Epoch 14/30: 100%|██████████| 63/63 [00:07<00:00,  8.34batch/s, loss=0.57]  \n",
      "Epoch 15/30: 100%|██████████| 63/63 [00:08<00:00,  7.06batch/s, loss=0.547] \n",
      "Epoch 16/30: 100%|██████████| 63/63 [00:08<00:00,  7.80batch/s, loss=0.515] \n",
      "Epoch 17/30: 100%|██████████| 63/63 [00:07<00:00,  7.97batch/s, loss=0.458] \n",
      "Epoch 18/30: 100%|██████████| 63/63 [00:07<00:00,  8.14batch/s, loss=0.43]  \n",
      "Epoch 19/30: 100%|██████████| 63/63 [00:09<00:00,  6.92batch/s, loss=0.46]  \n",
      "Epoch 20/30: 100%|██████████| 63/63 [00:08<00:00,  7.45batch/s, loss=0.413] \n",
      "Epoch 21/30: 100%|██████████| 63/63 [00:11<00:00,  5.29batch/s, loss=0.37]  \n",
      "Epoch 22/30: 100%|██████████| 63/63 [00:09<00:00,  6.49batch/s, loss=0.351] \n",
      "Epoch 23/30: 100%|██████████| 63/63 [00:09<00:00,  6.97batch/s, loss=0.403] \n",
      "Epoch 24/30: 100%|██████████| 63/63 [00:08<00:00,  7.53batch/s, loss=0.294] \n",
      "Epoch 25/30: 100%|██████████| 63/63 [00:07<00:00,  8.47batch/s, loss=0.288] \n",
      "Epoch 26/30: 100%|██████████| 63/63 [00:07<00:00,  8.29batch/s, loss=0.249] \n",
      "Epoch 27/30: 100%|██████████| 63/63 [00:07<00:00,  8.58batch/s, loss=0.283] \n",
      "Epoch 28/30: 100%|██████████| 63/63 [00:07<00:00,  8.51batch/s, loss=0.205] \n",
      "Epoch 29/30: 100%|██████████| 63/63 [00:07<00:00,  8.16batch/s, loss=0.179] \n",
      "Epoch 30/30: 100%|██████████| 63/63 [00:07<00:00,  8.54batch/s, loss=0.189] \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  \n",
    "  \n",
    "  with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as progress_bar:\n",
    "    for images, labels in train_dataloader:\n",
    "      images = images.float().to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      running_loss += loss.item()\n",
    "      progress_bar.set_postfix(loss=running_loss / (len(train_dataloader)))\n",
    "      progress_bar.update()\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for images, labels in test_dataloader:\n",
    "    images = images.float().to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "\n",
    "accuracy = 100 * correct / total \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.528662420382165"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2 (정확도 30.254777070063696)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "learning_rate = 0.0001\n",
    "batch_size = 20\n",
    "num_epochs = 30\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로\n",
    "data_path = 'C:/Users/jungh/final_project/eye_deeplearning'\n",
    "classes = ['spring', 'summer', 'fall', 'winter']\n",
    "num_classes = len(classes)\n",
    "image_size = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, images, labels):\n",
    "    self.images = images\n",
    "    self.labels = labels\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    image = self.images[idx]\n",
    "    label = self.labels[idx]\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1 = nn.BatchNorm2d(32)\n",
    "    self.relu1 = nn.ReLU()\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2 = nn.BatchNorm2d(64)\n",
    "    self.relu2 = nn.ReLU()\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc1 = nn.Linear(64 * (image_size[0] // 4) * (image_size[1] // 4), 64)\n",
    "    self.bn3 = nn.BatchNorm1d(64)\n",
    "    self.relu3 = nn.ReLU()\n",
    "    self.fc2 = nn.Linear(64, num_classes)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu1(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc1(x)\n",
    "    x = self.bn3(x)\n",
    "    x = self.relu3(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용\n",
    "def load_dataset():\n",
    "  x = []\n",
    "  y = []\n",
    "  \n",
    "  for i, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(data_path, class_name)\n",
    "    for image_name in os.listdir(class_path):\n",
    "      image_path = os.path.join(class_path, image_name)\n",
    "      image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "      image = cv2.resize(image, image_size)\n",
    "      x.append(image)\n",
    "      y.append(i)\n",
    "  \n",
    "  x = np.array(x)\n",
    "  y = np.array(y)\n",
    "  \n",
    "  return x, y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_dataset()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=SEED, stratify=y)\n",
    "\n",
    "x_train = x_train.reshape(-1, 3, image_size[0], image_size[1])\n",
    "x_test = x_test.reshape(-1, 3, image_size[0], image_size[1])\n",
    "\n",
    "# 텐서로 변환\n",
    "x_train = torch.from_numpy(x_train).float() / 255.0\n",
    "x_test = torch.from_numpy(x_test).float() / 255.0\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MyModel().float().to(device)\n",
    "model.conv1 = nn.Conv2d(x.shape[3], 32, kernel_size=3, stride=1, padding=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  \n",
    "  \n",
    "  with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as progress_bar:\n",
    "    for images, labels in train_dataloader:\n",
    "      images = images.float().to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      running_loss += loss.item()\n",
    "      progress_bar.set_postfix(loss=running_loss / (len(train_dataloader)))\n",
    "      progress_bar.update()\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8746503675356507"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for images, labels in test_dataloader:\n",
    "    images = images.float().to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "\n",
    "accuracy = 100 * correct / total \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 러닝레이트 0.0001 에폭 30 배치 20으로 햇을때 61.5퍼나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "learning_rate = 0.001\n",
    "batch_size = 20\n",
    "num_epochs = 50\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로\n",
    "data_path = 'C:/Users/jungh/final_project/eye_deeplearning'\n",
    "classes = ['spring', 'summer', 'fall', 'winter']\n",
    "num_classes = len(classes)\n",
    "image_size = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, images, labels):\n",
    "    self.images = images\n",
    "    self.labels = labels\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    image = self.images[idx]\n",
    "    label = self.labels[idx]\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1 = nn.BatchNorm2d(32)\n",
    "    self.relu1 = nn.ReLU()\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2 = nn.BatchNorm2d(64)\n",
    "    self.relu2 = nn.ReLU()\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc1 = nn.Linear(64 * (image_size[0] // 4) * (image_size[1] // 4), 64)\n",
    "    self.bn3 = nn.BatchNorm1d(64)\n",
    "    self.relu3 = nn.ReLU()\n",
    "    self.fc2 = nn.Linear(64, num_classes)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu1(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc1(x)\n",
    "    x = self.bn3(x)\n",
    "    x = self.relu3(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset():\n",
    "  x = []\n",
    "  y = []\n",
    "  \n",
    "  for i, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(data_path, class_name)\n",
    "    for image_name in os.listdir(class_path):\n",
    "      image_path = os.path.join(class_path, image_name)\n",
    "      image = cv2.imread(image_path)\n",
    "      image = cv2.resize(image, image_size)\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      x.append(image)\n",
    "      y.append(i)\n",
    "  \n",
    "  x = np.array(x)\n",
    "  y = np.array(y)\n",
    "  \n",
    "  return x, y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_dataset()\n",
    "# 데이터셋을 훈련 세트와 임시 데이터로 분할 (비율: 80% 훈련, 20% 임시 데이터)\n",
    "x_train_temp, x_test, y_train_temp, y_test = train_test_split(x, y, test_size = 0.2, random_state=SEED, stratify=y)\n",
    "\n",
    "# 임시 데이터를 다시 훈련 세트와 검증 세트로 분할 (비율: 75% 훈련, 25% 검증)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_temp, y_train_temp, test_size=0.25, random_state=SEED, stratify=y_train_temp)\n",
    "\n",
    "x_train = x_train.reshape(-1, 3, image_size[0], image_size[1])\n",
    "x_val = x_val.reshape(-1, 3, image_size[0], image_size[1])\n",
    "x_test = x_test.reshape(-1, 3, image_size[0], image_size[1])\n",
    "\n",
    "# 텐서로 변환\n",
    "x_train = torch.from_numpy(x_train).float() / 255.0\n",
    "x_val = torch.from_numpy(x_val).float() / 255.0\n",
    "x_test = torch.from_numpy(x_test).float() / 255.0\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_val = torch.LongTensor(y_val)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "val_dataset = CustomDataset(x_val, y_val)\n",
    "test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MyModel().float().to(device)\n",
    "model.conv1 = nn.Conv2d(x.shape[3], 32, kernel_size=3, stride=1, padding=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5e541014814712b46065641931d59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: Train Loss: 1.4182, Val Accuracy: 31.21%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff252cfbd2f424682fc8c0288b379dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: Train Loss: 1.2996, Val Accuracy: 28.23%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37e0c64cd6548ba864eeb6f64b5f520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: Train Loss: 1.2135, Val Accuracy: 29.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9157ee64fc44c8a698dc83168ce470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: Train Loss: 1.0686, Val Accuracy: 30.02%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c3cde72b84414b80fd90bfc59f56f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: Train Loss: 0.9298, Val Accuracy: 27.83%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c6ac65993245a29938591c3485aef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: Train Loss: 0.7195, Val Accuracy: 26.84%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8352e4839d403b8929f46e0ac5a01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: Train Loss: 0.5083, Val Accuracy: 29.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea8b27310274bc3a45c605abfe4bb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: Train Loss: 0.3468, Val Accuracy: 29.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c3d1fcd5944be998b4ab0325fa96b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: Train Loss: 0.2486, Val Accuracy: 30.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c804013af5f412a9ff5da4efb6c252a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: Train Loss: 0.1452, Val Accuracy: 31.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b487551c036b4c98949189d5664febc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: Train Loss: 0.0988, Val Accuracy: 28.83%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c000694fcde74664817b1bb6146537f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: Train Loss: 0.0623, Val Accuracy: 31.01%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd7614d686e475ca398715f540d2199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: Train Loss: 0.0641, Val Accuracy: 31.01%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617eb50301f24d0b856322bf5c0324bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: Train Loss: 0.0443, Val Accuracy: 31.01%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc95f328ec44e0fad0d4993f8c1084a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: Train Loss: 0.0527, Val Accuracy: 28.83%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f588e0318f47bba47ccf00b6da04aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: Train Loss: 0.0486, Val Accuracy: 29.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11da2ad8be864e199281261381703a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: Train Loss: 0.0475, Val Accuracy: 31.21%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602953f00cfd480e8c50b136b964376f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: Train Loss: 0.0774, Val Accuracy: 31.01%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2add9d0c1052467c9edc6ad73b65d947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: Train Loss: 0.0913, Val Accuracy: 32.41%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b23ca93774346ffb1949eff929dd94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: Train Loss: 0.0999, Val Accuracy: 31.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7c1d72614e458e81b908621fd0e9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: Train Loss: 0.0828, Val Accuracy: 29.82%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5ab9bc4dc44531a77a42fb56ec50fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: Train Loss: 0.0740, Val Accuracy: 29.03%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba3a21dec1642f7904a081e7deeafa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: Train Loss: 0.0688, Val Accuracy: 30.62%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae828ada70c940e894efa505016c7334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: Train Loss: 0.0430, Val Accuracy: 29.42%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6816c5c43a4c48f8abd848174fc61ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: Train Loss: 0.0583, Val Accuracy: 31.81%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4649adf203348a9bc6c7c6c739468a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: Train Loss: 0.0299, Val Accuracy: 31.41%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a223c2b90ab04af7ba733c7c854d9087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: Train Loss: 0.0372, Val Accuracy: 29.82%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6a87a93647488fbb2e233da932d2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: Train Loss: 0.0490, Val Accuracy: 31.41%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235d9f8fca784dc8842299a0246cca4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: Train Loss: 0.0496, Val Accuracy: 31.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c90086314345ef91716e0b7e84213c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: Train Loss: 0.0237, Val Accuracy: 30.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b2dae538d94cfa8589f826d026955e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: Train Loss: 0.0151, Val Accuracy: 30.82%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ce7ac3336d4dc0a2655638875858ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: Train Loss: 0.0097, Val Accuracy: 31.01%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76b8b47374b47a6a24075e710d1003d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: Train Loss: 0.0123, Val Accuracy: 32.01%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fffbdcbee7f4cb8bd7b4db702f12450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: Train Loss: 0.0231, Val Accuracy: 30.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346a7908916f481d8d97e5b780851c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: Train Loss: 0.0499, Val Accuracy: 29.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183a3ad7bb4f482d87ccabf2450edad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: Train Loss: 0.0472, Val Accuracy: 32.41%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6856b931dd3c4c6ab449c48270703bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: Train Loss: 0.0422, Val Accuracy: 29.82%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1738409634704211a962fef9ed0054a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: Train Loss: 0.0266, Val Accuracy: 31.01%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80144fb5376c4aa0ae1a4723cffcd556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: Train Loss: 0.0332, Val Accuracy: 31.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfdd5f1cb2414fd88d1e160a6481a8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: Train Loss: 0.0398, Val Accuracy: 33.80%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb43783b0194cc8bdd9a59fadf6745f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: Train Loss: 0.0330, Val Accuracy: 32.80%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a20e18092b4b108cb6ec4208fa9a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: Train Loss: 0.0303, Val Accuracy: 31.01%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a99a98b27244c895eb3c71b783919e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: Train Loss: 0.0169, Val Accuracy: 33.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a10b2c9aee345fcad11ea68e14cdc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: Train Loss: 0.0162, Val Accuracy: 30.82%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5d8339f1d54864ba52a98a202ad3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: Train Loss: 0.0195, Val Accuracy: 31.21%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b42cd4145e449ea56870ba2240ec81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: Train Loss: 0.0270, Val Accuracy: 32.80%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ec7ed94cfd4852b60897c736985e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: Train Loss: 0.0254, Val Accuracy: 31.01%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5101476b61d54b2e8da65884cb72ceb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: Train Loss: 0.0303, Val Accuracy: 31.21%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2584ae2409df425eb798cf92ca0fe00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: Train Loss: 0.0379, Val Accuracy: 30.42%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a10e9ccb4c240508502b2315d045ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/50:   0%|          | 0/76 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: Train Loss: 0.0514, Val Accuracy: 28.83%\n"
     ]
    }
   ],
   "source": [
    "best_val_accuracy = 0.0\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = [] \n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  correct_train = 0\n",
    "  total_train = 0  \n",
    "  \n",
    "  with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as progress_bar:\n",
    "    for images, labels in train_dataloader:\n",
    "      images = images.float().to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      running_loss += loss.item()\n",
    "      progress_bar.set_postfix(loss=running_loss / (len(train_dataloader)))\n",
    "      progress_bar.update()\n",
    "      _, predicted_train = torch.max(outputs.data, 1)\n",
    "      total_train += labels.size(0)\n",
    "      correct_train += (predicted_train == labels).sum().item()\n",
    "  epoch_loss = running_loss / len(train_dataloader)\n",
    "  train_losses.append(epoch_loss)              \n",
    "  train_accuracy = 100 * correct_train / total_train\n",
    "  train_accuracies.append(train_accuracy)\n",
    "  \n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  val_loss = 0.0\n",
    "\n",
    "  \n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for images, labels in val_dataloader:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      val_loss += loss.item() \n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "  val_accuracy = 100 * correct / total\n",
    "  val_loss /= len(val_dataloader)\n",
    "  val_losses.append(val_loss)\n",
    "  val_accuracies.append(val_accuracy)\n",
    "  print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {epoch_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# 검증 세트의 정확도가 이전에 기록한 최고 정확도보다 높으면 모델 저장\n",
    "  if val_accuracy > best_val_accuracy:\n",
    "      best_val_accuracy = val_accuracy\n",
    "      torch.save(model.state_dict(), 'best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHACAYAAACVhTgAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACB30lEQVR4nOzdd3RU1d7G8e+k9xACKUho0ntTmiAKgoBIU1GRooiigAVQLlZQr3ivDb0qiiKIqKBSxBdFEAgogkoVASkaCCUh1HQyycx5/zhhINRMMsmkPJ+1Zs2c/hs4Yp7ss/e2GIZhICIiIiIiIpfk4e4CRERERERESjoFJxERERERkStQcBIREREREbkCBScREREREZErUHASERERERG5AgUnERERERGRK1BwEhERERERuQIFJxERERERkSvwcncBxc1ut3P48GGCg4OxWCzuLkdERERERNzEMAxSU1OpUqUKHh6Xb1Mqd8Hp8OHDxMTEuLsMEREREREpIQ4cOEDVqlUvu0+5C07BwcGA+YcTEhLi5mpERERERMRdUlJSiImJcWSEyyl3wenM43khISEKTiIiIiIikq8uPBocQkRERERE5AoUnERERERERK5AwUlEREREROQKyl0fp/wwDIOcnBxsNpu7S5EyxtPTEy8vLw2FLyIiIlLKKDidx2q1kpCQQEZGhrtLkTIqICCA6OhofHx83F2KiIiIiOSTgtM57HY7cXFxeHp6UqVKFXx8fNQyIC5jGAZWq5WjR48SFxdHnTp1rjjRmoiIiIiUDApO57BardjtdmJiYggICHB3OVIG+fv74+3tzf79+7Farfj5+bm7JBERERHJB/26+yLUCiBFSfeXiIiISOlTYn6CmzJlChaLhccee+yy+61evZpWrVrh5+dHrVq1eP/994unQBERERERKbdKRHD6/fffmT59Ok2bNr3sfnFxcfTs2ZOOHTuyefNmnnrqKR555BHmz59fTJWKiIiIiEh55PbglJaWxqBBg/jwww8JCwu77L7vv/8+1apVY+rUqTRo0ID777+f++67j9dee62Yqi1fOnfufMUWQBERERGR8sDtwWnUqFH06tWLrl27XnHfdevW0a1btzzrunfvzoYNG8jOzi6qEks8i8Vy2dewYcMKdN4FCxbw4osvFqq2YcOG0bdv30KdQ0RERETE3dw6qt7cuXPZuHEjGzZsyNf+iYmJREZG5lkXGRlJTk4Ox44dIzo6+oJjsrKyyMrKciynpKQUrugSKCEhwfF53rx5PPfcc+zatcuxzt/fP8/+2dnZeHt7X/G8FStWdF2RIiIiIiIAOVaw54BP6RrF2m0tTgcOHODRRx/ls88+c2pI5vPnVTIM46Lrz5gyZQqhoaGOV0xMjFN1GoZBhjXHLa8z3+1KoqKiHK/Q0FAsFotj+fTp01SoUIEvv/ySzp074+fnx5w5czh+/Dh33XUXVatWJSAggCZNmvDFF1/kOe/5j+rVqFGDl19+mfvuu4/g4GCqVavG9OnTnfrzPN/q1au59tpr8fX1JTo6mn/961/k5OQ4tn/99dc0adIEf39/wsPD6dq1K+np6QDExsZy7bXXEhgYSIUKFejQoQP79+8vVD0iIiIiUsSW/gtm3AQn4txdiVPc1uK0ceNGkpKSaNWqlWOdzWZjzZo1vPPOO2RlZeHp6ZnnmKioKBITE/OsS0pKwsvLi/Dw8IteZ+LEiYwdO9axnJKS4lR4ysy20fC5H/K9vyvteKE7AT6u+SuaMGECr7/+OjNnzsTX15fTp0/TqlUrJkyYQEhICEuWLGHw4MHUqlWLNm3aXPI8r7/+Oi+++CJPPfUUX3/9NQ899BCdOnWifv36Ttd06NAhevbsybBhw5g9ezZ//fUXI0aMwM/Pj0mTJpGQkMBdd93Ff//7X/r160dqaio//fQThmGQk5ND3759GTFiBF988QVWq5XffvtNExaLiIiIlGSbPoUNMwALHNsNFWu6u6J8c1tw6tKlC9u2bcuz7t5776V+/fpMmDDhgtAE0K5dO7799ts865YtW0br1q0v+eiZr68vvr6+riu8lHrsscfo379/nnXjx493fB4zZgxLly7lq6++umxw6tmzJw8//DBghrE333yT2NjYAgWn9957j5iYGN555x0sFgv169fn8OHDTJgwgeeee46EhARycnLo378/1atXB6BJkyYAnDhxguTkZG655RauvvpqABo0aOB0DSIiIiJSTA5uhCW5DRo3PAV1u7u3Hie5LTgFBwfTuHHjPOsCAwMJDw93rJ84cSKHDh1i9uzZAIwcOZJ33nmHsWPHMmLECNatW8eMGTMueMTMlfy9Pdnxgnv+Uv29LwyPBdW6des8yzabjVdeeYV58+Zx6NAhR1+wwMDAy57n3CHjzzwSmJSUVKCadu7cSbt27fK0EnXo0IG0tDQOHjxIs2bN6NKlC02aNKF79+5069aN2267jbCwMCpWrMiwYcPo3r07N910E127duWOO+64aD83EREREXGztCSYdw/YrFCvF3Qcf+VjShi3j6p3OQkJCcTHxzuWa9asyXfffUdsbCzNmzfnxRdf5O2332bAgAFFVoPFYiHAx8stL1c+dnZ+IHr99dd58803efLJJ1m5ciVbtmyhe/fuWK3Wy57n/JY9i8WC3W4vUE2GYVy2z5qnpyfLly/n+++/p2HDhvzvf/+jXr16xMWZz8POnDmTdevW0b59e+bNm0fdunVZv359gWoRERERkSJiy4avhkHqYQivA/3eB48SHUMuyq2j6p0vNjY2z/KsWbMu2Of6669n06ZNxVNQGfbTTz/Rp08f7rnnHgDsdjt79uwp1sfdGjZsyPz58/MEqF9++YXg4GCuuuoqwAxQHTp0oEOHDjz33HNUr16dhQsXOvqttWjRghYtWjBx4kTatWvH559/Ttu2bYvtO4iIiIjIFSx7FvavBZ9guPNz8Atxd0UFUqKCkxSf2rVrM3/+fH755RfCwsJ44403SExMLJLglJyczJYtW/Ksq1ixIg8//DBTp05lzJgxjB49ml27dvH8888zduxYPDw8+PXXX1mxYgXdunUjIiKCX3/9laNHj9KgQQPi4uKYPn06t956K1WqVGHXrl3s3r2bIUOGuLx+ERERESmgrXPh12nm537vQ+W67q2nEBScyqlnn32WuLg4unfvTkBAAA888AB9+/YlOTnZ5deKjY2lRYsWedYNHTqUWbNm8d133/HEE0/QrFkzKlasyPDhw3nmmWcACAkJYc2aNUydOpWUlBSqV6/O66+/To8ePThy5Ah//fUXn3zyCcePHyc6OprRo0fz4IMPurx+ERERESmAw1vg20fNz52egAa3uLWcwrIY+Z0sqIxISUkhNDSU5ORkQkLyNhOePn2auLg4atas6dTcUiLO0H0mIiIiZV76cZjeGZLjoU43uGsueLhu4DNXuVw2OF/p65UlIiIiIiIlly0Hvr7XDE0Va0H/D0tkaHKWgpOIiIiIiLjOikkQtxq8A2HgZ+Bfwd0VuYSCk4iIiIiIuMaf8+GX/5mf+74LkQ3dW48LKTiJiIiIiEjhJf4J34w2P3d4DBr1c2s5rqbgJCIiIiIihZNxAuYNguwMuPpG6PKcuytyOQUnEREREREpOLsNFoyAk/ugQnUYMKNMDAZxPgUnEREREREpuFX/hr0/gpc/3PkZBFR0d0VFQsFJREREREQKZsc38NPr5udb/wdRTdxbTxFScBKHzp0789hjjzmWa9SowdSpUy97jMViYdGiRYW+tqvOIyIiIiLFJOkvWPSw+bndaGh6u3vrKWIKTmVA79696dq160W3rVu3DovFwqZNm5w+7++//84DDzxQ2PLymDRpEs2bN79gfUJCAj169HDptc43a9YsKlSoUKTXEBERESkXTifD3LvBmgY1O0HXye6uqMgpOJUBw4cPZ+XKlezfv/+CbR9//DHNmzenZcuWTp+3cuXKBAQEuKLEK4qKisLX17dYriUiIiIihWC3w8KRcOJvCKkKt80ETy93V1XkFJzKgFtuuYWIiAhmzZqVZ31GRgbz5s1j+PDhHD9+nLvuuouqVasSEBBAkyZN+OKLLy573vMf1duzZw+dOnXCz8+Phg0bsnz58guOmTBhAnXr1iUgIIBatWrx7LPPkp2dDZgtPpMnT2br1q1YLBYsFouj5vMf1du2bRs33ngj/v7+hIeH88ADD5CWlubYPmzYMPr27ctrr71GdHQ04eHhjBo1ynGtgoiPj6dPnz4EBQUREhLCHXfcwZEjRxzbt27dyg033EBwcDAhISG0atWKDRs2ALB//3569+5NWFgYgYGBNGrUiO+++67AtYiIiIiUWD+9Dru+A09fGPgpBFZyd0XFouxHw8IyDHM8enfwDgCL5Yq7eXl5MWTIEGbNmsVzzz2HJfeYr776CqvVyqBBg8jIyKBVq1ZMmDCBkJAQlixZwuDBg6lVqxZt2rS54jXsdjv9+/enUqVKrF+/npSUlDz9oc4IDg5m1qxZVKlShW3btjFixAiCg4N58sknGThwIH/++SdLly7lxx9/BCA0NPSCc2RkZHDzzTfTtm1bfv/9d5KSkrj//vsZPXp0nnC4atUqoqOjWbVqFXv37mXgwIE0b96cESNGXPH7nM8wDPr27UtgYCCrV68mJyeHhx9+mIEDBxIbGwvAoEGDaNGiBdOmTcPT05MtW7bg7e0NwKhRo7BaraxZs4bAwEB27NhBUFCQ03WIiIiIlGh7lpuj6AHc8gZc5fxTTaWVgtOVZGfAy1Xcc+2nDoNPYL52ve+++3j11VeJjY3lhhtuAMzH9Pr3709YWBhhYWGMHz/esf+YMWNYunQpX331Vb6C048//sjOnTvZt28fVatWBeDll1++oF/SM8884/hco0YNxo0bx7x583jyySfx9/cnKCgILy8voqKiLnmtzz77jMzMTGbPnk1goPn933nnHXr37s1//vMfIiMjAQgLC+Odd97B09OT+vXr06tXL1asWFGg4PTjjz/yxx9/EBcXR0xMDACffvopjRo14vfff+eaa64hPj6eJ554gvr16wNQp04dx/Hx8fEMGDCAJk3MkWRq1arldA0iIiIiJdqJf2D+cMCA1vdBi3vcXVGx0qN6ZUT9+vVp3749H3/8MQB///03P/30E/fddx8ANpuNf//73zRt2pTw8HCCgoJYtmwZ8fHx+Tr/zp07qVatmiM0AbRr1+6C/b7++muuu+46oqKiCAoK4tlnn833Nc69VrNmzRyhCaBDhw7Y7XZ27drlWNeoUSM8Pc9OrhYdHU1SUpJT1zr3mjExMY7QBNCwYUMqVKjAzp07ARg7diz3338/Xbt25ZVXXuHvv/927PvII4/w0ksv0aFDB55//nn++OOPAtUhIiIi5VR2Juz8FpaMg5X/hu2L4Nhec3LZksCaAfMGm4NCVL0Gbn7F3RUVO7U4XYl3gNny465rO2H48OGMHj2ad999l5kzZ1K9enW6dOkCwOuvv86bb77J1KlTadKkCYGBgTz22GNYrdZ8ndswjAvWWc57jHD9+vXceeedTJ48me7duxMaGsrcuXN5/fXXnfoehmFccO6LXfPMY3LnbrPb7U5d60rXPHf9pEmTuPvuu1myZAnff/89zz//PHPnzqVfv37cf//9dO/enSVLlrBs2TKmTJnC66+/zpgxYwpUj4iIiJQDWWmw5wfYsRj2LLt49xAvf4ioD5GNILIxRDQ03wPDi69Ow4BvH4Ejf0JgZbhjNniVv0G9FJyuxGLJ9+Ny7nbHHXfw6KOP8vnnn/PJJ58wYsQIxw/9P/30E3369OGee8wmVbvdzp49e2jQoEG+zt2wYUPi4+M5fPgwVaqYjy6uW7cuzz5r166levXqPP30045154/05+Pjg812+d+cNGzYkE8++YT09HRHq9PatWvx8PCgbt26+arXWWe+34EDBxytTjt27CA5OTnPn1HdunWpW7cujz/+OHfddRczZ86kX79+AMTExDBy5EhGjhzJxIkT+fDDDxWcREREJK/MU7B7qRmW/l4BOafPbgutBvV7gjUdknbAkR2QkwmHN5uvcwVFQWTDvIGqcn3w8nF9zb9+ANu+Aosn3P4JhLipG4ubKTiVIUFBQQwcOJCnnnqK5ORkhg0b5thWu3Zt5s+fzy+//EJYWBhvvPEGiYmJ+Q5OXbt2pV69egwZMoTXX3+dlJSUPAHpzDXi4+OZO3cu11xzDUuWLGHhwoV59qlRowZxcXFs2bKFqlWrEhwcfMEw5IMGDeL5559n6NChTJo0iaNHjzJmzBgGDx7s6N9UUDabjS1btuRZ5+PjQ9euXWnatCmDBg1i6tSpjsEhrr/+elq3bk1mZiZPPPEEt912GzVr1uTgwYP8/vvvDBgwAIDHHnuMHj16ULduXU6ePMnKlSvz/WcrIiIiZVz6cdi1xAxL/8SC/ZxRgCteDQ37QMNbIbp53oHB7DY4uc9s6TmyI/d9O5yMg7RE8/X3yrP7B0dDv/ehVmfX1b5vLSzL/Zmv20tQo4Przl3KKDiVMcOHD2fGjBl069aNatWqOdY/++yzxMXF0b17dwICAnjggQfo27cvycnJ+Tqvh4cHCxcuZPjw4Vx77bXUqFGDt99+m5tvvtmxT58+fXj88ccZPXo0WVlZ9OrVi2effZZJkyY59hkwYAALFizghhtu4NSpU8ycOTNPwAMICAjghx9+4NFHH+Waa64hICCAAQMG8MYbbxTqzwYgLS2NFi1a5FlXvXp19u3bx6JFixgzZgydOnXCw8ODm2++mf/9738AeHp6cvz4cYYMGcKRI0eoVKkS/fv3Z/Jkc7I3m83GqFGjOHjwICEhIdx88828+eabha5XRERESqnUI/DX/8GOb2Dfz2Cc88RN5QZmUGrYx2wputQoyh6eEH61+WrY5+z6rDQ4+tfZIHVkOyT+CakJMLsvdBwLnZ8q/NxKKYfhq2Fgz4HGt0Hbhwp3vlLOYlys80oZlpKSQmhoKMnJyYSEhOTZdvr0aeLi4qhZsyZ+fn5uqlDKOt1nIiIiZZjdDj88Bb++D5zzY3ZUEzP8NOgDlYug64E1A5b+CzZ9Yi7HtIEBH0GFapc/7lJysmBWLzj4O0Q0gvuXl5ruK864XDY4n1qcRERERERcwW6HJY/Dxlnm8lWtcsNSb6hYxFOV+ATArW+bj+l9+ygc+BXevw5ufcds3XLW0olmaPILhTvnlMnQ5CwFJxERERGRwrLbYclYMzRZPKDv+9BsYPHX0bi/OSnt1/fBoY3w5WBoPRy6/xu8/fN3js1zYMMMwAL9Pyr60FdKaB4nEREREZHCsNvhu3GwcaZ7Q9MZYTXgvh+gw6Pm8oYZ8GEXOLrrsocB5uh9/zfW/Nx5ItTtVmRlljYKTiIiIiIiBWUY8N142PAxYHF/aDrD0xtuegHumQ8BlSBpO0zvDJs+NWu+mPTj5iS3tiyoezN0eqJYSy7pFJxERERERArCMGDJuLOPtfUrIaHpXLW7wkNroeb15gS7i0fD/PvhdEre/Ww58PW9kHzAfDSv3wfgoahwLv1pXEQ5G2hQipnuLxERkTLA0dKUG5r6ToNmd7q7qosLjoLBi6DLc+Yktn9+DR90NPtAnbHyRYhbDd4BMPAz8K/grmpLLAWnc3h7ewOQkZHh5kqkLDtzf52530RERKSUMQz47gn4/SPM0PQeNL/L3VVdnocHdBwH934PodXMiXVndINf/gfbF8LaqeZ+fd6ByIburLTE0qh65/D09KRChQokJSUB5kSslktNSCbiJMMwyMjIICkpiQoVKuDp6enukkRERMRZjtD0IWCBPu9C87vdXVX+VWsDI9fA4kdg52JY9szZbe1GQ+MB7quthFNwOk9UVBSAIzyJuFqFChUc95mIiIiUIoYB3z95Tmh6B1oMcndVzvMPgztmmwNaLJ1oDgZRoyN0nezuyko0BafzWCwWoqOjiYiIIDs7293lSBnj7e2tliYREZHSyDDg+wnw23TAArf+D1rc4+6qCs5igWuGQ/X2sGcZtBwCnooGl+PWP51p06Yxbdo09u3bB0CjRo147rnn6NGjx0X3j42N5YYbbrhg/c6dO6lfv75La/P09NQPuCIiIlJ8DANs2eDl4+5K5HyGAUv/Bb99YC7f+j9oOdi9NblKRAPzJVfk1uBUtWpVXnnlFWrXrg3AJ598Qp8+fdi8eTONGjW65HG7du0iJCTEsVy5cuUir1VERESkSC16CHZ+C7e+rX4mJYlhmI+z/fq+uVyWQpM4xa3BqXfv3nmW//3vfzNt2jTWr19/2eAUERFBhQoVirg6ERERkWKy50fY+oX5ef79kJ1Zuh8DKwo7/w8St0GHR8EnoHiuaRjww1Pw6zRzuffb5iNtUi6VmOHIbTYbc+fOJT09nXbt2l123xYtWhAdHU2XLl1YtWpVMVUoIiIiUgRs2fDDRPNzhWpg2OGbUfDrdPfWVZKcOgBfDYPVr8Cn/SDzVNFf0zDgh6dh/Xvmcu+3oNXQor+ulFhuD07btm0jKCgIX19fRo4cycKFC2nY8OJjx0dHRzN9+nTmz5/PggULqFevHl26dGHNmjWXPH9WVhYpKSl5XiIiIiIlxu8fwbHdEBAOD/4EbR8213//BPz0hntrKynWvAr23EG7DqyHT26BtCIcATn7NMwfDuvfNZdvmQqthhXd9aRUsBiGYbizAKvVSnx8PKdOnWL+/Pl89NFHrF69+pLh6Xy9e/fGYrGwePHii26fNGkSkydfOLRicnJynn5SIiIiIsUu/Tj8rwWcTjZ/OG99r9nSseplWPNfc5+O4+HGZ8xR0MqjE3HwTmuw50Cv1yH2FUg/ChWvhiHfQIUY114v7SjMvRsO/gYeXubjeaVxyHHJl5SUFEJDQ/OVDdze4uTj40Pt2rVp3bo1U6ZMoVmzZrz11lv5Pr5t27bs2bPnktsnTpxIcnKy43XgwAFXlC0iIiJSeKv+bYamyCZn+85YLHDj02fn1PnpNXNwAvf+rtt91rxmhqaru8A198N9P0BoDJz4Gz7uDkd3u+5aSX/BR13M0OQXCoMXKjSJg9uD0/kMwyArKyvf+2/evJno6OhLbvf19SUkJCTPS0RERMTtjmyHjTPNzzdPAY/zpkG57jHo+Zr5+ddp8O0jYLcVa4mXZcsp+msc//vsoBk3PGW+h19thqdKdSHlEMy8GQ5vKfy1/l4FM7rBqf0QVhPuXwE1OxX+vFJmuHVUvaeeeooePXoQExNDamoqc+fOJTY2lqVLlwJma9GhQ4eYPXs2AFOnTqVGjRo0atQIq9XKnDlzmD9/PvPnz3fn1xARERFxzpl5gQw7NLgVana8+H7XjgCfQHOwiE2zwZoB/d4HT+/irfdcthxY8jj8uRAGfAj1Lj7/pkus/g8YNqjTHaq2Prs+9Cq493uYMwAStsCsW+DueVCjQ8Gus3EW/N9Y81oxbeHOzyEw3BXfQMoQtwanI0eOMHjwYBISEggNDaVp06YsXbqUm266CYCEhATi4+Md+1utVsaPH8+hQ4fw9/enUaNGLFmyhJ49e7rrK4iIiIg4768lELcGPH2h24uX37f53eDtbw5T/ufX5lDlt88EL9/iqfVcZwZN+Ov/zOXFj8Do38A/zPXXOroLtn1lfr5h4oXbAyvB0G/hi7tg/88wpz/cMRvqds//Nex2+PE5+OV/5nKTO6DPO+75s5USz+2DQxQ3ZzqAiYiIiLhcTha8ey2c3Acdx0GX5/J33O4fYN5gsGXB1TfCwM+Kbz4jgKw0c9CEuNXg6QOBlc1H5VoNM4fqdrWv74M/50O9XnDX55feLzvTHKp891JzMId+H0CT2658fms6LHjgbAjs/BRc/2T5HYSjnCpVg0OIiIiIlCvr3zNDU1AUXDc2/8fV7Q6DvgLvQPh7pfmY2ulimmYl86Q5f1LcavP6g76CAR+Z2zbOgv2/uPZ6R3bAnwvMz53/dfl9vf1h4ByztcieY7bM/f7R5Y9JSYCZPc3Q5OkD/T+CzhMUmuSyFJxEREREikvqEXOUOICuk8A3yLnja11vjvTmGwrxv8DsWyHjhMvLzCMtCWb1PjvS3JBvoFZnqN7+7NxG3z5qtqS5yupXAMPs/xXd9Mr7e3qbLU3XjDCPWzLO/HO+2INVidvMkfMStphzZw39Fpre7rrapcxScBIREREpLiteAGsaXNUKmg4s2DmqtYGhi8G/IhzebA6MUFSTwZ46ADN7wJFtEBgBw76DmGvObu86GYIizQl8XTVZb8IfsOMbwAKdL9K36VI8PKDnq9DpCXN55Yuw/Nm84Wn3D/DxzeYjhpXqwv0/QrW2rqlbyjwFJxEREZHicGgTbPnM/HzzK+YP+gVVpbk5qlxQFCRtN8PA8b9dUqbDsb25591rzpt031KIapx3H/8K0OM/5uefXjcHdCis2FfM98b9IbKhc8daLOZkwd3+bS7/8j9YPMYcxv3XD+CLO83gWrMTDF8GFWsVvl4pNxScRERERIqaYZiT2GKYfXFiri38OSPqw33fQ2g1czLYd64xBztI2ln4cyf+ac6PlHIQwmuboSn86ovv27Av1O0B9mxzlD27veDXPbwZdi0Biwdcf4W+TZfTfjTc+o55ns2fwntt4fsnzeHfWwyGexYUzUiAUqYpOImIiIgUtT/nw4H14B1g9m1ylYq1zPBUu6s5B9Ef88yQMHcQHNpYsHMe+B1m9YT0oxDVBO5dCqFVL72/xQK9XgOfIPM7bppVsOsCrJpivje5HSrXLfh5AFoOhttnmYM/HNttrrvpBbj1f+6dB0tKLQUnERERkaJkzYDluUOOX/e4OXmrK4VWhXvmwwOx5mAKWMzR4j68EWb3MeeLyu/sM//EmsecToaYNjD0/yCocv5quPFZ8/Py581R65x1cAPs+QEsnnD9BOePv5iGfcwRAM8M397hUY2cJwWm4CQiIiJSlH552xyMIDQG2o8puutUaQEDP4VRv0Kzu80A8k8sfNIbZtwEu76/fID6awl8djtkp0OtG8zR+/wr5P/6144wB73ISjEfi3PWqtx+Sc3uvPRjgQVRq7P5XRrc4rpzSrmk4CQiIlIeGQYc3W12mpeik3wQfp5qfr7pBXPOoaJWuR70mwaPbDaH5/b0hYO/mwMjvH8dbPv6wr/3rfNyJ9e1Qv1b4O554BPo3HU9PKH32+YktDsXm0Esv/avM+em8vA6OyqeSAmj4CQiIlLenBmo4N1r4PM7wJbj7orKruXPQ04mVGsPjfoV77XDqpt9jx7bBh0eA59gOPInzB8O77SGjZ+Ycy/99iEsfMDsI9XsLrj9E/DyLdg1oxqfbVVbMj7/E/TGvmy+Nx8EFWsW7NoiRcxiGPl96LVsSElJITQ0lOTkZEJCQtxdjoiISPFb/d+zj0UBtB0FN7/svnrKqvj18HF3wGL2P6rS3L31ZJ40Q9L698zPAAGVIOOY+fnaB+Dm/xRumHSA7Ex4rx2cjINrH4Se/738/nE/wSe3gIc3PLIJKlQr3PVFnOBMNlCLk4iISHny24dnQ1OT28339e/Cpk/dV1NZZLfD97kDHLS4x/2hCczht69/Eh77E7q/DMHRZ0NTpyegx38LH5rAfByx91Tz82/TzVH6LsUwYFVuaG85RKFJSjQFJxERkfJi29fwXW7/kesnwICPzs6V83+Pmy0kZYndDhtnwepXIcdavNfe+gUkbDEfj+vyXPFe+0p8g6DdKHh0K/T7wHw078ZnXDvaXK3O5gAVGPDtI2DLvvh+/8RC/C/mkOEdx7nu+iJFQMFJRESkPNjzIyx8EDDgmvuh80Rz/fUTzCGs7dkw7x44dcCtZbrMyX3m41/fPgqrXoIvh0D26eK5dlYqrJhsfr7+CQiKKJ7rOsvL1xzBrlHfojl/t5cgIBySdpgjC57v3NamVve6fph2ERdTcBIRESnr4n81Q5E9BxoPgB6vnm1d8PCAfu+bE52mH4Uv7gJrunvrLQzDgA0z4b32sH8teAeClx/s/t4cVc6aUfQ1/PQ6pB0xJ6dtM7Lor1dSBYbDza+Yn2P/A8f/zrt97wo4+Jv599NxbPHXJ+IkBScREZGy7Mh2+Px2c2S32l2h7/sX9mPxCYQ7v4DAynBkGywcaT7mVtqkHIbPboP/e8yci6hae3horTkBqncg/LPK3J6VWnQ1/PEl/PKO+bnbvws+Ol1Z0eR2c/JZW5bZ+ndmTDLDONvX7pr7ITjKfTWK5JOCk4iISFl1ch982h9OJ0PVa+GO2eDlc/F9K8TAwDnmyGY7F8Pq/xRrqYViGGZgea8t7P3RnLeo+8swbIk5tHXNTuYEqL4hZivU7L6Qecq1NdiyzcEgFowwH3ts2Bfq9XDtNUojiwV6vQFe/rDvJ9jyubl+91I4vAm8A6DDo+6tUSSfFJxERETKorQkMyCkJUJEw/xNaFqt7dnR0Fa/AtsXuramw1vgl/+Zjw66qkUr/Rh8OdgMLKeToUoLGPmTOfjBuS1r1drA0MXmyHKHNsAnvSH9uGtqSD0Cn9wKv75vLnd6Am772LWDLZRmFWvCDU+Zn5c9bd6bZ1qbrh1RcvuAiZxH8ziJiIiUNZmnYNYt5mN3FarDfT9ASHT+j1/6lDlEuZc/DP8BopsVsp6TsOIFs+8RuT92BEdDg97QsA9Uawcens6fd+f/mY9/ZRwDDy9zhMDrHgdPr0sfk/gnfNrX7M9VuQEM+QaCIwvyrUwHfjMHnkhNMEfQ6/8B1O9V8POVVbYc+LAzJG6DSnXh2G7wCYJH/zD7Qom4iTPZQMFJRESkLLFmwJwB5hDPgRFw31IIv9q5c9hy4PM74O8VEFIVHlhVsFYBu90clnv5c2fnC6rW3vzh2XpOP6PAylD/Fmh4K9ToCJ7elz9v5ilY+i/z3GC2qPV7P/8B7+humH2rGXYqXm22RIVWde67GQZs+Nh8PM+eDZXrm486Vqrj3HnKk0Ob4KMuYOS2NnYcV/KGapdyR8HpMhScRESkzLLlDim+eyn4hsK9S8zR8goi8xR81BWO7zH7Rw37P+cGOkj8E5aMgwO5c0NVrg89X4OaHSEny5y/Z8c38NcSOH3q7HH+YVCvl9kSVev6C6+5dwV8MxpSD4PFw+wf03mi84MwnPgHPukDyfHmpKtDv4WwGvk7NjsTloyHLXPM5YZ9oM+74BvsXA3l0ZnWTN8Qcx6pgIrurkjKOQWny1BwEhGRMsluh0Uj4Y955vDOgxdC9faFO+exvfDRjWbfoeaDzHBwpX47p1Mgdgr8+gEYNnM0u84ToO3DF29JsmVD3JqzIepMyxSYP1zX62HOM1WtndkvZsMMc1vFq81WpphrC/79Th0wW55O/APBVczwVKn2FY6Jh3mDzcltLR7QdRK0f0T9mfLLmmH+PdboCPVudnc1IgpOl6PgJCIiZY5hwNKJ8Os0sHjCXV9A3e6uOffeFeYQ3obdHF67/ehL1/DnfPjhaXNACjBbYrpPyf/EprYc8xHDHYth57dnz3O+ax+Ers9febCL/EhNhNl94Ohf5qONQ76ByIYX3/fvVfD1fZB5Avwrwu0zoVbnwtcgIm6j4HQZCk4iIlLmrHkVVr5kfu43HZoNdO35108z+xRZPODur6BO17zbj+6G78aZLUdgTvza81Vz3qiCstvNyVF3fGMGqZSDEBpjtnrVur7g572Y9GPmCIRHtpmBaPBCqNL87HbDgLVvwYrJZoCMbg4DPzUf8RORUk3B6TIUnEREpMzIPAXr3jGDE8DN/4G2I11/HcOAxWNg86dm36kRK8xBEKzp5rV/ecccIMHLz+zw3/4R8PZz7fVP7oOQKkU3oWzmSXNQjUMbze94z3yIucacLHfRw+bcVgDN74Fer7v2+4mI2yg4XYaCk4iIlHqn4mH9+7DpE7Cmmes6PQk3Pl1018zJMucqOrDe7F/U+V/mEOPJB8ztdbpDj/+Yc/aUVqdT4POB5uOCPkFmq9nat8zH+Dy8oed/odW96s8kUoYoOF2GgpOIiJRaCVvNCWT/XGAOvADmUNwdHoOmdxT9D/RpR+HDG86GJYDQatDjFajXs2wECms6zL3bHPXvjOBouONTswVKRMoUZ7LBZWaIExEREbczDHOAhl/ehrjVZ9fXvN58JK52l+ILLEGVzYEnPr7ZbIHq8Ah0HA8+AcVz/eLgEwh3zTMntd3zA1TvALfNLNwkuSJSJqjFSUREpCTKscKfX5stTEk7zHUWT2jcH9qNzjt4QXFLzR3tLjjKfTUUNbsNjmw3W/Q89XtmkbJKLU4iIiKlVeYp2DgLfn0fUhPMdT5B0HKoOfBDSRjJrSwHpjM8PCG6qburEJESRMFJRETE3QzDnIT19xl5B3wIijLDUqt7wb+CW0sUESnvFJxERESKS3YmHP8bju2G43vN92O74dheyE4/u1/lBtB+DDS5Hbx83FeviIg4KDiJiIi4kmFA+tFzQtGe3NducxhxLtG12OIJNa4zA1PtrmVjhDoRkTLErcFp2rRpTJs2jX379gHQqFEjnnvuOXr06HHJY1avXs3YsWPZvn07VapU4cknn2TkyCKY7E9ERMQZGSfg5zfNSWIzT156P79QqFQ391XHfA+vA2E11LokIlKCuTU4Va1alVdeeYXatWsD8Mknn9CnTx82b95Mo0aNLtg/Li6Onj17MmLECObMmcPatWt5+OGHqVy5MgMGDCju8kVERMx5f9a/B2v/B1nJuSstEFb9bCg6E5Aq1YXASmpNEhEphUrccOQVK1bk1VdfZfjw4RdsmzBhAosXL2bnzp2OdSNHjmTr1q2sW7cuX+fXcOQiIuISOVZzIIfV/4X0JHNdZGO48RmodQN4+7m3PhERuaJSORy5zWbjq6++Ij09nXbt2l10n3Xr1tGtW7c867p3786MGTPIzs7G29u7OEoVEZHSICUBVkw2h86u1wuuagUeHoU/r90G276GVf+GU/vNdWE14MZnoVF/11xDRERKHLcHp23bttGuXTtOnz5NUFAQCxcupGHDhhfdNzExkcjIvDN3R0ZGkpOTw7Fjx4iOjr7gmKysLLKyshzLKSkprv0CIiJS8pyKh09uhZNx5vLPb0JQJNS9Ger3gpqdwNvfuXMaBuz+AVa8AEnbzXVBkXD9k9BiiPoniYiUcW4PTvXq1WPLli2cOnWK+fPnM3ToUFavXn3J8GQ577nwM08anr/+jClTpjB58mTXFi0iUp5kpULyIUg5BCmH4XQy1O8JFWu5u7KLO/63GZpSDkKF6mZL094fIe2I+Wjdpk/AOwCuvtEMUXW6Q2D45c+5/xf4cRIc+NVc9guFDo9BmwfBJ7Cov5GIiJQAJa6PU9euXbn66qv54IMPLtjWqVMnWrRowVtvveVYt3DhQu644w4yMjIu+qjexVqcYmJi1MdJRATMEJRy2AxFyYfOfj4TklIOQ9ZFWuq9/OCGp6Htw+Dp9t/BnZX0F8zuA2mJ5qAMQxdDSBWzP9K+n2DXd7Dre/P7nWHxgGrtoF5PqNcDwq8+uy3hD1j5IuxZZi57+ZsT0nZ4FPzDive7iYiIy5XKPk5nGIaRJ+icq127dnz77bd51i1btozWrVtfsn+Tr68vvr6+Lq9TRKTUsmXD0n/B1nlgTc3fMb6hEHqVGUJOJ8PB32H5s/DnfOjzDkQ1Kdqa8yPhD/i0L2Qch4hGMGQRBEWY27x8oHYX89XzNUjYaoaov76DI9tg/1rztexpqFzfDFGn4uHPr83jLZ7Qaih0ehJCLnwsXEREyj63tjg99dRT9OjRg5iYGFJTU5k7dy6vvPIKS5cu5aabbmLixIkcOnSI2bNnA+Zw5I0bN+bBBx9kxIgRrFu3jpEjR/LFF1/kezhyjaonIuVaVhp8OQT+XnF2nV8FCMkNRaFXnf0ccuZzNPgGn93fMMy5in54xhx+28PLbIHp9KT7RpI7uBHm9DNDXXRzGLwQAirm79iT+2H3UvhriRme7Dl5tzceYLaundsSJSIiZYIz2cDp4JSZmYlhGAQEBACwf/9+x4AO5494dyXDhw9nxYoVJCQkEBoaStOmTZkwYQI33XQTAMOGDWPfvn3ExsY6jlm9ejWPP/64YwLcCRMmODUBroKTiJRb6cfgs9vh8Cazj0+/D8x+Pr5BBTtfaiJ8Nx525j4JEF4Hbv0fVL/4yKhFZv8v8NkdZutZTBsY9JXZB6kgMk/Cnh9h9/dmK1P70RDdzLX1iohIiVGkwalbt27079+fkSNHcurUKerXr4+3tzfHjh3jjTfe4KGHHipU8UVNwUlEyqWT++DT/nDib/CvaIaLqq1dc+4di80AlXbEXL7mfujyPPgVw7+xf6+CuXdDdgbU6Ah3zS14EBQRkXLHmWzg9GQTmzZtomPHjgB8/fXXREZGsn//fmbPns3bb79dsIpFRKToJG6DGd3M0BQaA8OXuS40ATS8FUb9Ci0Gm8u/fwTvtTWH7i5Ku3+Azweaoal2VzMMKjSJiEgRcTo4ZWRkEBxsPuu+bNky+vfvj4eHB23btmX//v0uL1BERAoh7ieY2dNsDYpoBMOXQ6U6rr+Of5g5SMSQxeZksCmH4PM7YP795iOCrrZ9kdnSZMuC+rfAnZ87Py+TiIiIE5wOTrVr12bRokUcOHCAH374wdGvKSkpSY++iYiUJNsXwZz+5nDi1TvAvd8V/Yhwta6Hh9ZB+zHmMN/bvoJ3roE/vjQHlXCFrfPg63vNQRwaD4DbZ4GXRk8VEZGi5XRweu655xg/fjw1atSgTZs2tGtndgJetmwZLVq0cHmBIiJSAL99CF8NA5sVGvSGexaAf4XiubZPAHR7Ce7/ESIbQ+YJWDDCHJjiyA6w2wp+7o2zYOGDYNih+SDo/yF4Xnw6ChEREVcq0HDkiYmJJCQk0KxZMzw8zOz122+/ERISQv369V1epCtpcAgRKdMMA1b9G9a8ai63vs+ct8jD0z312LJh7VRY/V8zxAF4+kB4bahcDyrVg8p1zffw2pcfznz9+7B0gvn5mvuhx6vg4fTv/0RERByKdFS9i11s5cqV1KtXjwYNGhTmVMVCwUlEikROFnz7qDn5au+3zHmQipstB5Y8DpvMue/o/BRc/yRYLMVfy/mO7jYn3d3/C+RkXnwfi4fZP+pMmKpc3/xcqQ5smAE/TjL3azfabNEqCd9LRERKtSINTnfccQedOnVi9OjRZGZm0qxZM/bt24dhGMydOzffE9G6i4KTiLic3Wb2udnxjbkcHA13zyve+X+sGTB/OOz6zgwgvd6A1vcW3/Xzy26H5HgzSB3bBUf/Ovv5dPKVj+/0JNzwlEKTiIi4hDPZwMvZk69Zs4ann34agIULF2IYBqdOneKTTz7hpZdeKvHBSUTEpQwDlow1Q5OHN1SIgRP/wMc3w4AZUL9n0deQcQK+uBMO/AqevnDbx9DglqK/bkF45LYqhdWAuudMmm4Y5sh/R3fBsd3m+9G/zM9pR8wweOOz0HGsuyoXEZFyzunglJycTMWKFQFYunQpAwYMICAggF69evHEE0+4vEARkRJt5UvmgAVYYMBHUKuzOSjDP7kTs3b/N7R9uOhaSJIPwpwBZsjwCzUngK3evmiuVZQsFgiOMl+1rs+7LfOkGawCKrqnNhEREQowql5MTAzr1q0jPT2dpUuXOoYjP3nyJH5+l+nUKyJS1qx7F356zfx8y5vQqK85ct2gr6DVMMCAH56CJePM/keuZBhmK9dHN5mhKbgK3Lu0dIamK/EPU2gSERG3c7rF6bHHHmPQoEEEBQVRvXp1OnfuDJiP8DVp0sTV9YmIlExbvjBDEZiPkJ3bn8jTG26ZCuF1YNkz5sAGJ+PM+Yb8Qgt/7cRt8P2/YP/P5nKluuZw4xViCn9uERERuagCjaq3YcMGDhw4wE033URQUBAAS5YsoUKFCnTo0MHlRbqSBocQkULb9T3MHQSGDdqOMh/Hu9SjeDv/z5zDKDsDKjcwB40Iq16w66Yfg5UvmqPmGXbw8oP2j8B1j4FPYIG/joiISHlVbMORnznUUopGN1JwEpFC2f8LfNoPck5D0zuh77QrzyV0eDN8fiekJUJgZbMfUtXW+b9mjhV+m27OhZSVO/Jco/5w02SoUK3g30VERKSccyYbFGjmwNmzZ9OkSRP8/f3x9/enadOmfPrppwUqVkSk1EjcZgagnNNQ92bo807+JmCt0gJGrITIJpB+FGb1gu0Lr3ycYcDuH2BaO1j2tBmaopvBvd/D7TMVmkRERIqR032c3njjDZ599llGjx5Nhw4dMAyDtWvXMnLkSI4dO8bjjz9eFHWKiLjXiX/g0/5meKnWzuyv5Omd/+NDr4L7lppzLe1eao68d+IfuG7sxR/zO7rL7EO190dzObAydHkemt8NHp6u+EYiIiLiBKcf1atZsyaTJ09myJAhedZ/8sknTJo0ibi4OJcW6Gp6VE9EnJaaCDO6wan9ENkYhi0xR88rCLvNHDBi/XvmcvNB5kASXj7mcuZJiH0FfvvQ7EPl4Q3tHoaO48FP/2aJiIi4UpFOgJuQkED79hcOd9u+fXsSEhKcPZ2ISMmWedJsaTq135y09Z4FBQ9NYLYW3TwFKtaC75+ELZ/Byf1mC9aORbDqZcg8Ye5brxd0exHCry789xAREZFCcbqPU+3atfnyyy8vWD9v3jzq1KnjkqJEREoEa4bZpylpOwRFwuBFEBzpmnNfOwLu/gp8gs1hxd9oAN+NN0NT5Qbmte76XKFJRESkhHC6xWny5MkMHDiQNWvW0KFDBywWCz///DMrVqy4aKASESmVbNlmP6QD68E31GxpqljTtdeo0xWG/wCfD4TkA+ZErzc8Da3uBU+n/3kWERGRIlSg4cg3btzIm2++yc6dOzEMg4YNGzJu3DhatGhRFDW6lPo4icgV2e2waCT8Mc+cK2nwIqjeruiul34M9iwzR+oLqFh01xEREZE8im0ep3MdOXKEDz74gOeee84VpysyCk4iclnWDPhxEvz2AVg84a4voG53d1clIiIiRcAtwWnr1q20bNkSm83mitMVGQUnEcnjdDIc+A32rzUntz20CezZ5rZ+06HZQPfWJyIiIkWmSEfVExEp1dKPQ/wvZkjav9ac1Naw590nuArcMFGhSURERBwUnESkbEs5fDYk7f8Fjv514T4Va0H19lC9g/leofrFJ6UVERGRckvBSURKL7sdMo6Z4Sg1EVITznklwrHdcHLfhcdFNMwNSu2hWnsIiS720kVERKR0yXdwGjt27GW3Hz16tNDFiIhcIGknHN58kXCUCGlHwJ5z+eMtHhDd7GxrUrV2GrlOREREnJbv4LR58+Yr7tOpU6dCFSMi4mC3wer/wur/AJcbw8ZiTk4bHAXB0WbrUXC0uRwaA1e1Aj8NBCMiIiKFk+/gtGrVqqKsQ0TkrLQkmH8/xK02l6u1NyefPROIzg1IgRGaLFZERESKnH7aEJGSJe4nmD/cfAzPOwBueROa3enuqkRERKScU3ASkZLBboefXofYl83hwSs3gDs+gcr13F2ZiIiIiIKTiJQAaUdhwQj4J/eR4OaDoOer4BPo3rpEREREcik4iYh77VtrPpqXmgBe/tDrdWgxyN1ViYiIiOSh4CQi7mG3w9o3YeVL5qN5lerC7Z9AZEN3VyYiIiJygQIFp1OnTvHbb7+RlJSE3W7Ps23IkCEuKUxEyrD047DwQdi73FxuOhB6vQG+Qe6tS0REROQSnA5O3377LYMGDSI9PZ3g4GAsFotjm8VicSo4TZkyhQULFvDXX3/h7+9P+/bt+c9//kO9epfuDB4bG8sNN9xwwfqdO3dSv359576MiBS/+PXw9X2Qcgi8/KDHf6HlEDjn3xIRERGRksbD2QPGjRvHfffdR2pqKqdOneLkyZOO14kTJ5w61+rVqxk1ahTr169n+fLl5OTk0K1bN9LT06947K5du0hISHC86tSp4+xXEZHiZLfDz1NhZk8zNIXXhvtXQKuhCk0iIiJS4jnd4nTo0CEeeeQRAgICCn3xpUuX5lmeOXMmERERbNy4kU6dOl322IiICCpUqFDoGkSkGGSeggUPwJ4fzOXGA6D3W+Ab7NayRERERPLL6Ran7t27s2HDhqKoheTkZAAqVqx4xX1btGhBdHQ0Xbp0YdWqVZfcLysri5SUlDwvESlGmafg075maPL0NSe0HTBDoUlERERKFadbnHr16sUTTzzBjh07aNKkCd7e3nm233rrrQUqxDAMxo4dy3XXXUfjxo0vuV90dDTTp0+nVatWZGVl8emnn9KlSxdiY2Mv2ko1ZcoUJk+eXKCaRKSQMk/Bp/3g8GYICId75kOVFu6uSkRERMRpFsMwDGcO8PC4dCOVxWLBZrMVqJBRo0axZMkSfv75Z6pWrerUsb1798ZisbB48eILtmVlZZGVleVYTklJISYmhuTkZEJCQgpUq4jkw+lkMzQd2gj+FWHotxB16V+KiIiIiBS3lJQUQkND85UNnG5xOn/4cVcYM2YMixcvZs2aNU6HJoC2bdsyZ86ci27z9fXF19e3sCWKiDNOJ8On/XNDUxgMXazQJCIiIqWaWyfANQyDMWPGsHDhQmJjY6lZs2aBzrN582aio6NdXJ2IFMjpFJgzAA5tMEPTkMUQ1cTdVYmIiIgUSoGC0+rVq3nttdfYuXMnFouFBg0a8MQTT9CxY0enzjNq1Cg+//xzvvnmG4KDg0lMTAQgNDQUf39/ACZOnMihQ4eYPXs2AFOnTqVGjRo0atQIq9XKnDlzmD9/PvPnzy/IVxERVzoTmg7+Dn4VYMg3EN3U3VWJiIiIFJrTo+rNmTOHrl27EhAQwCOPPMLo0aPx9/enS5cufP75506da9q0aSQnJ9O5c2eio6Mdr3nz5jn2SUhIID4+3rFstVoZP348TZs2pWPHjvz8888sWbKE/v37O/tVRMSVslLhs9vg4G/nhKZm7q5KRERExCWcHhyiQYMGPPDAAzz++ON51r/xxht8+OGH7Ny506UFupozHcBEJJ+yUmHObXBgPfiFmqFJo+eJiIhICedMNnC6xemff/6hd+/eF6y/9dZbiYuLc/Z0IlLaZaXBZ7efDU2DFyk0iYiISJnjdHCKiYlhxYoVF6xfsWIFMTExLilKREqJM6Epfh34hsLghXBVS3dXJSIiIuJyTg8OMW7cOB555BG2bNlC+/btsVgs/Pzzz8yaNYu33nqrKGoUkZLImg6fD4T4X8A3JDc0tXJ3VSIiIiJFwung9NBDDxEVFcXrr7/Ol19+CZj9nubNm0efPn1cXqCIlEBnQtP+n8+GpqoKTSIiIlJ2OT04RGmnwSFECsmaAZ/fAft+Ap9gMzTFXOPuqkREREScVqSDQ4hIOWbNgC8GnhOaFig0iYiISLmQr0f1KlasyO7du6lUqRJhYWFYLJZL7nvixAmXFScibpaTBQlbzQltD/wG8eshLRF8guCe+RBzrbsrFBERESkW+QpOb775JsHBwY7PlwtOIlJKGQYkHzRD0pmglPgH2Kx59/OrAHfPg2pt3FKmiIiIiDuoj5NIeZWdCYe35Aal3+DgBkhNuHC/gHCoeq35SF7Va8yR83wCi71cEREREVdzJhs4Paqep6cnCQkJRERE5Fl//PhxIiIisNlszp5SRJxlt0PcavhnFWSfBns22LLBnpP7ng22nEuszzYfwTvxt7n+XBZPiGpsBqWq15hhKawmqJVZREREyjmng9OlGqiysrLw8fEpdEEichkph2HLZ7DpUzi1v/DnC4ww+ylVbW2GpSotwCeg8OcVERERKWPyHZzefvttACwWCx999BFBQUGObTabjTVr1lC/fn3XVyhS3tlyYM8y2PSJ+W7YzfW+odDwVgiKAA9v8PTKffe+yLLXOetzlyvWhArV1ZokIiIikg/5Dk5vvvkmYLY4vf/++3h6ejq2+fj4UKNGDd5//33XVyhSXp34BzbPgc2fmSPZnVGtPbQcAg37qHVIREREpJjkOzjFxcUBcMMNN7BgwQLCwsKKrCiRcisnC3Z+C5tmm32YzgioBM3vghZDoHJd99UnIiIiUk453cdp1apVRVGHSPmWtNMMS1u/gMyTuSstcPWNZutSvZ7gpT6EIiIiIu7idHACOHjwIIsXLyY+Ph6rNe8cL2+88YZLChMpF9KPw8IHYO+PZ9eFXAUt7jFfFaq5rzYRERERcXA6OK1YsYJbb72VmjVrsmvXLho3bsy+ffswDIOWLVsWRY0iZdORHfDFQDgVbw7WUPdmaDkUancBD88rHy8iIiIixcbD2QMmTpzIuHHj+PPPP/Hz82P+/PkcOHCA66+/nttvv70oahQpe3Z9DzNuMkNTWE0YuRbu/AzqdlNoEhERESmBnA5OO3fuZOjQoQB4eXmRmZlJUFAQL7zwAv/5z39cXqBImWIY8POb8MVdYE2DGh1hxEqI0FD+IiIiIiWZ08EpMDCQrKwsAKpUqcLff//t2Hbs2DHXVSZS1mSfhoUPwo+TAANaD4fBCyGgorsrExEREZErcLqPU9u2bVm7di0NGzakV69ejBs3jm3btrFgwQLatm1bFDWKlH6pR2Du3XBoA1g8ocd/4NoR7q5KRERERPLJ6eD0xhtvkJaWBsCkSZNIS0tj3rx51K5d2zFJroic4/AWMzSlHAK/CnDHJ1Crs5uLEhERERFnWAzDMNxdRHFKSUkhNDSU5ORkQkJC3F2OlHXbF8LChyAnE8LrwN3zIPxqd1clIiIiIjiXDQo0j5OIXIHdDmv+C7FTzOXaXWHADPCv4NayRERERKRg8hWcwsLCsFgs+TrhiRMnClWQSKlnTYdFD8GOb8zldqPhphc0zLiIiIhIKZav4DR16lTH5+PHj/PSSy/RvXt32rVrB8C6dev44YcfePbZZ4ukSJFSI/mgOdR44h/g4Q23vAktB7u7KhEREREpJKf7OA0YMIAbbriB0aNH51n/zjvv8OOPP7Jo0SJX1udy6uMkRebA7+YgEOlJEBAOAz+D6u3cXZWIiIiIXIIz2cDpeZx++OEHbr755gvWd+/enR9//NHZ04mUDdsXwqxeZmiKaAQjVik0iYiIiJQhTgen8PBwFi5ceMH6RYsWER4e7pKiREqVXz+Ar+4FWxbU6wnDf4Cw6u6uSkRERERcyOlR9SZPnszw4cOJjY119HFav349S5cu5aOPPnJ5gSIllmHAihfg5zfM5Wvuhx7/1SAQIiIiImWQ08Fp2LBhNGjQgLfffpsFCxZgGAYNGzZk7dq1tGnTpihqFCl5bNmw+BHY+rm5fOMz0HE85HP0SREREREpXTQBroizrOnw5VDYuxwsntB7KrQc4u6qRERERMRJLp8ANyUlxXGilJSUy+6rMCJlWvpx+Px2OLQRvPzh9llQ78LBUkRERESkbMnX4BBhYWEkJSUBUKFCBcLCwi54nVnvjClTpnDNNdcQHBxMREQEffv2ZdeuXVc8bvXq1bRq1Qo/Pz9q1arF+++/79R1RQrk5D74uJsZmvzDYOhihSYRERGRciJfLU4rV66kYsWKAKxatcplF1+9ejWjRo3immuuIScnh6effppu3bqxY8cOAgMDL3pMXFwcPXv2ZMSIEcyZM4e1a9fy8MMPU7lyZQYMGOCy2kTySNwGcwZA2hEIjYF75kPleu6uSkRERESKSYnq43T06FEiIiJYvXo1nTp1uug+EyZMYPHixezcudOxbuTIkWzdupV169Zd8Rrq4yROi1sDcwdBVoo5R9M9X0NIFXdXJSIiIiKF5PI+Tn/88Ue+L960adN873u+5ORkAEfr1sWsW7eObt265VnXvXt3ZsyYQXZ2Nt7e3nm2ZWVlkZWV5Vi+Uh8tkTz+XAALHwSbFap3gDs/B/8K7q5KRERERIpZvoJT8+bNsVgsXKlxymKxYLPZClSIYRiMHTuW6667jsaNG19yv8TERCIjI/Osi4yMJCcnh2PHjhEdHZ1n25QpU5g8eXKBapJy7tcP4PsJgAENboX+H4K3n7urEhERERE3yFdwiouLK+o6GD16NH/88Qc///zzFfe1nDdXzplAd/56gIkTJzJ27FjHckpKCjExMYWsVso0TWwrIiIiIufJV3CqXr16kRYxZswYFi9ezJo1a6hatepl942KiiIxMTHPuqSkJLy8vAgPD79gf19fX3x9fV1ar5RhmthWRERERC4iX8HpYnbs2EF8fDxWqzXP+ltvvTXf5zAMgzFjxrBw4UJiY2OpWbPmFY9p164d3377bZ51y5Yto3Xr1hf0bxJxSk6WObHt7u9zJ7Z9C1oOdndVIiIiIlICOB2c/vnnH/r168e2bdvy9Hs685icM32cRo0axeeff84333xDcHCwoyUpNDQUf39/wHzU7tChQ8yePRswR9B75513GDt2LCNGjGDdunXMmDGDL774wtmvInJW9mmYdw/sXQ5efnD7J5qjSUREREQc8jUB7rkeffRRatasyZEjRwgICGD79u2sWbOG1q1bExsb69S5pk2bRnJyMp07dyY6OtrxmjdvnmOfhIQE4uPjHcs1a9bku+++IzY2lubNm/Piiy/y9ttvaw4nKbjsTJh7V25o8oe7v1RoEhEREZE8nJ7HqVKlSqxcuZKmTZsSGhrKb7/9Rr169Vi5ciXjxo1j8+bNRVWrS2geJ8nDmgFfDDTnavIOhEFfQo3r3F2ViIiIiBQDZ7KB0y1ONpuNoKAgwAxRhw8fBswBJHbt2lWAckXcJCsNPr/DDE0+QXDPfIUmEREREbkop/s4NW7cmD/++INatWrRpk0b/vvf/+Lj48P06dOpVatWUdQo4npZqfDZ7RC/DnyCYfACiLnW3VWJiIiISAnldHB65plnSE9PB+Cll17illtuoWPHjoSHh+fpmyRSYp1OgTkD4OBv4Btqhqaqrd1dlYiIiIiUYPkOTs2bN+f+++9n0KBBhIWFAVCrVi127NjBiRMnCAsLu+gEtCIlSuYpMzQd2gB+FWDwQriqpburEhEREZESLt99nNq0acMzzzxDlSpVuPvuu1mxYoVjW8WKFRWapOTLOAGf9jVDk38YDF2s0CQiIiIi+ZLv4PTBBx+QmJjI9OnTSUxMpFu3btSoUYMXXnghz3DhIiVSxgmY3QcOb4aAcBj6LUQ3c3dVIiIiIlJKODWqnp+fH4MHD2blypXs3buXwYMHM2PGDGrVqkX37t358ssvi6pOkYJLPwaf9IbEPyCwMgz9P4hq4u6qRERERKQUcXoep/MZhsH8+fN58MEHOXXqFDabzVW1FQnN41TOpB2F2bdC0g4IijRbmirXc3dVIiIiIlICOJMNnB5V71yrVq1i5syZLFiwAC8vL0aMGFGY04m4VuoRs6Xp2C4IioJh/weV6ri7KhEREREphZwOTvHx8cyaNYtZs2axb98+OnbsyHvvvcftt9+Ov79/UdQo4ryUBDM0Hd8DwVXM0BR+tburEhEREZFSKt/B6fPPP2fmzJmsWrWKyMhIhgwZwvDhw6ldu3ZR1ifinPRjsPULWP8+pByE0Bhz9LyKmpxZRERERAou38Fp2LBh9OrVi0WLFtGzZ088PJwaV0Kk6NjtsO8n2DgLdn4L9mxzfYXqZp+msOpuLU9ERERESr98B6eDBw8SERFRlLWIOCctCbZ8Bptmw4l/zq6v0hJaDYXGt4FvkPvqExEREZEyI9/BSaFJSgS7HeJizdalv5aAPcdc7xMMTe8wA5PmZxIRERERFyvUqHoixSY1ETbPMVuXTu0/u77qNdBqGDTqBz6BbitPRERERMo2BScpuex2+HslbJwJu74HI3eOMN9QaDYQWg6FqMburVFEREREygUFJymZDvwOS/8FhzacXRfT1nwUr2Ff8AlwW2kiIiIiUv4oOEnJknwQfpwE274yl70DoeUQMzBFNHBraSIiIiJSfuUrOIWFhWGxWPJ1whMnThSqICmnrBnwy9vw81TIyQQs0HwQdHkWgqPcXZ2IiIiIlHP5Ck5Tp051fD5+/DgvvfQS3bt3p127dgCsW7eOH374gWeffbZIipQyzG6HP782W5lSDpnrqrWDm6dAlRZuLU1ERERE5AyLYRiGMwcMGDCAG264gdGjR+dZ/8477/Djjz+yaNEiV9bncikpKYSGhpKcnExISIi7yynfDm6A7yec7ccUWg26vWD2YcpnC6eIiIiISEE5kw2cDk5BQUFs2bKF2rVr51m/Z88eWrRoQVpamvMVFyMFpxIg+RCsmAx/zDOXvQOh41hoNxq8/dxbm4iIiIiUG85kAw9nTx4eHs7ChQsvWL9o0SLCw8OdPZ2UJ9YMiH0F/tfqbGhqPgge2QSdxis0iYiIiEiJ5fSoepMnT2b48OHExsY6+jitX7+epUuX8tFHH7m8QCkDDAO2fQ0/Pn+2H1NMW+jxivoxiYiIiEip4HRwGjZsGA0aNODtt99mwYIFGIZBw4YNWbt2LW3atCmKGqU0OxUPCx+C/T+by6HV4KbJ0Kif+jGJiIiISKnhdB+n0k59nIrRH1/CknGQlZLbj+nx3H5M/u6uTERERETEqWxQoAlw7XY7e/fuJSkpCbvdnmdbp06dCnJKKUsyT5mB6c+vzeWq10L/D6BiLbeWJSIiIiJSUE4Hp/Xr13P33Xezf/9+zm+sslgs2Gw2lxUnpdC+tbDwQUg+ABZPuP5J6DgePAuU0UVERERESgSnf5odOXIkrVu3ZsmSJURHR2NRPxUByLFC7Mvw81TAgLAa0P8jiLnGzYWJiIiIiBSe08Fpz549fP311xfM4yTl2LE9MP9+SNhiLje/xxwxzzfYrWWJiIiIiLiK08GpTZs27N27V8FJzGHGN3wMPzwNOZngVwFufRsa9nF3ZSIiIiIiLuV0cBozZgzjxo0jMTGRJk2a4O3tnWd706ZNXVaclGDpx+Cb0bD7e3O55vXQ730IqeLeukREREREioDTw5F7eHhceBKLBcMwSsXgEBqO3AX2LIdFD0N6Enj6QJfnoe3DcJF7Q0RERESkpCrS4cjj4uIKXNj51qxZw6uvvsrGjRtJSEhg4cKF9O3b95L7x8bGcsMNN1ywfufOndSvX99ldcklZGfC8ufgt+nmcuUGMOBDiGri3rpERERERIqY08GpevXqLrt4eno6zZo1495772XAgAH5Pm7Xrl15EmHlypVdVpNchGHA7qWw/Hk4tstc1+Yh6DoJvP3cWpqIiIiISHEo8OQ6O3bsID4+HqvVmmf9rbfemu9z9OjRgx49ejh97YiICCpUqOD0ceIkw4C/V8Kqf8Ohjea6oEjo+x7U7ure2kREREREipHTwemff/6hX79+bNu2zdG3CXDM51QcfZxatGjB6dOnadiwIc8888xFH987Iysri6ysLMdySkpKkddXJuxbCytfgvhfzGXvAGjzILR/BAIqurc2EREREZFi5nRv/kcffZSaNWty5MgRAgIC2L59O2vWrKF169bExsYWQYlnRUdHM336dObPn8+CBQuoV68eXbp0Yc2aNZc8ZsqUKYSGhjpeMTExRVpjsbFmQPpx15/34AaY3Rdm9TRDk6evOfDDo1vNR/MUmkRERESkHHJ6VL1KlSqxcuVKmjZtSmhoKL/99hv16tVj5cqVjBs3js2bNxesEIvlioNDXEzv3r2xWCwsXrz4otsv1uIUExNTekfVs2XDr+9D7CtgTYPK9c2hwGtdDzWuA7/Qgp03YSusetnsywTg4Q0th0Cn8RpiXERERETKpCIdVc9msxEUFASYIerw4cPUq1eP6tWrs2vXroJVXAht27Zlzpw5l9zu6+uLr69vMVZUhPb/AkvGQdKOs+uO/mW+fvsALB5QpcXZIBXT9sqDNyTtNAPTztzgafGEZnfB9U9AWI0i+yoiIiIiIqWJ08GpcePG/PHHH9SqVYs2bdrw3//+Fx8fH6ZPn06tWrWKosbL2rx5M9HR0cV+3WKVdtQcBnzr5+ayf0W46QWo1xP2/wz/rIa41XB8rzmIw6GN8PMb5mN21drkBqnOEN0cPHP/yo//bbZabfsKMAALNLkNrv8XVKrtnu8pIiIiIlJCOR2cnnnmGdLT0wF46aWXuOWWW+jYsSPh4eHMmzfPqXOlpaWxd+9ex3JcXBxbtmyhYsWKVKtWjYkTJ3Lo0CFmz54NwNSpU6lRowaNGjXCarUyZ84c5s+fz/z58539GqWD3QYbPoaVL8LpZMACrYaaE86e6WvUsI/5Akg+CHFrzgap1ARzOW6NeQ7fEPNxPp8g+HM+GLkDeTS4FTpPhMiGbvmaIiIiIiIlndPBqXv37o7PtWrVYseOHZw4cYKwsDDHyHr5tWHDhjwj4o0dOxaAoUOHMmvWLBISEoiPj3dst1qtjB8/nkOHDuHv70+jRo1YsmQJPXv2dPZrlBhxx9KpWSnwwg2HNsL/jYWELeZydDPo9SZUbXXpk4VWheZ3my/DgGN7zAD1Tyzs+8kMX7u+O7t/ne5ww1NQpbkLv5GIiIiISNnj9OAQpZ0zHcCK2rq/jzPoo/UMaVeDf/Woj5+3J2ScgBUvwMZZgAG+odDlWWh9H3h4Fvxidps5AETcarNlqulAiLnWVV9FRERERKTUKdLBIcR1NsWfxG7ArF/28evfR5nVci+Rv74MGbnDjDe9E7q9CEERhb+Yhydc1dJ8iYiIiIiIUxSc3GjUDbVpGB3CB19+w/iT04lctRsAo3IDLL1ehxod3FyhiIiIiIiAgpN7nU7hhn1v0tn4AIuHjXTDl6k5A0gMvZeXIltQwBmZRERERETExTzcXUC5tuIFWP8eFsOG0aAPC9ovYqbRm2//PErPt35i4/4T7q5QREREREQo4OAQu3fvJjY2lqSkJOx2e55tzz33nMuKKwolaXAIUo/A53eYgz/U7grAlgOneOSLzcSfyMDTw8LjXevwUOfaeHo4N2KhiIiIiIhcnjPZwOng9OGHH/LQQw9RqVIloqKi8gxBbrFY2LRpU8GqLiYlKjiBOWz4ecO4p57O5umFf7J462EA2taqyNSBLYgK9XNHhSIiIiIiZVKRBqfq1avz8MMPM2HChEIV6S4lLjhdgmEYzN90iOe++ZMMq40KAd68elszbmoY6e7SRERERETKBGeygdN9nE6ePMntt99e4OIkfywWC7e1qsr/jbmOxleFcCojmxGzN/D8N39yOtvm7vJERERERMoVp4PT7bffzrJly4qiFrmIWpWDmP9Qe+6/riYAn6zbT99317LnSKqbKxMRERERKT+cHo68du3aPPvss6xfv54mTZrg7e2dZ/sjjzzisuLE5OvlyTO3NKRDnUqM/3IrfyWm0vudn3m6ZwPuurYaXp4aHFFEREREpCg53cepZs2alz6ZxcI///xT6KKKUmnp43QpSamnGfflVn7acwyAqysHMq5bPXo0zjtQh4iIiIiIXF6RDg5R2pX24ARgtxt8sm4fb6/Yw8mMbACaXBXKE93r0bFOJQUoEREREZF8UHC6jLIQnM5IPZ3Nhz/FMeOnf0i3mgNGtKsVzpM316NFtTA3VyciIiIiUrK5PDiNHTuWF198kcDAQMaOHXvZfd944w3nqi1mZSk4nXEsLYt3V+3ls/XxWG3mhMQ3NYzkie71qBsZ7ObqRERERERKJmeyQb4Gh9i8eTPZ2dmOz5eiR8Tco1KQL8/3bsTw62ry1o97mL/pIMt3HOHHnUfo1+IqHu9al5iKAe4uU0RERESk1NKjemXQ3qRUXl+2m+//TATA29PC3ddWY/SNdagc7Ovm6kRERERESgb1cbqM8hCczth64BSv/rCLn/eaI/D5e3sy/LqajOhUi1B/7yscLSIiIiJSthV5cPr999/56quviI+Px2q15tm2YMECZ09XrMpTcDrjl73H+M8Pu9h64BQAof7eTB3YnBvqR7i3MBERERERN3ImGzg9c+rcuXPp0KEDO3bsYOHChWRnZ7Njxw5WrlxJaGhogYuWotO+diUWPdyeDwa3ok5EEMmZ2dw/ewPzfo93d2kiIiIiIqWC08Hp5Zdf5s033+T//u//8PHx4a233mLnzp3ccccdVKtWrShqFBewWCx0bxTFd492ZEDLqtjsBhPmb+PN5bspZ09rioiIiIg4zeng9Pfff9OrVy8AfH19SU9Px2Kx8PjjjzN9+nSXFyiu5e3pwWu3N2XMjbUBeGvFHv41fxs5ucOYi4iIiIjIhZwOThUrViQ1NRWAq666ij///BOAU6dOkZGR4drqpEhYLBbGdavHv/s1xsMC8zYcYMTsDWRYc9xdmoiIiIhIieR0cOrYsSPLly8H4I477uDRRx9lxIgR3HXXXXTp0sXlBUrRGdSmOh8Mbo2ftwerdh3lrunrOZaW5e6yRERERERKHKdH1Ttx4gSnT5+mSpUq2O12XnvtNX7++Wdq167Ns88+S1hYWFHV6hLlcVS9K9kUf5Lhs37nZEY21cMD+OTea6lRKdDdZYmIiIiIFKkiG448JyeHzz77jO7duxMVFVXoQt1Bweni/jmaxtCZv3HgRCYVA334eNg1NI+p4O6yRERERESKTJENR+7l5cVDDz1EVpYe5ypralUOYsFDHWhyVSgn0q3cNX09K3YecXdZIiIiIiIlgtN9nNq0acPmzZuLohZxs8rBvsx9oC3X161MZraNEbM38MVvmutJRERERMTL2QMefvhhxo0bx8GDB2nVqhWBgXn7wjRt2tRlxUnxC/T14qOhrXlqwTa+2niQiQu2kZB8mse71sFisbi7PBERERERt8h3H6f77ruPqVOnUqFChQtPYrFgGAYWiwWbzebqGl1KfZzyxzAM3ly+m7dX7gXgjtZV+Xe/Jnh7Ot1IKSIiIiJSIhXJ4BCenp4kJCSQmZl52f2qV6+e/0rdQMHJOZ//Gs8zi7ZhN6Bzvcq8e3dLAn2dbqgUERERESlxnMkG+f4J+Ey+KunBSFzr7jbViAj2ZfQXm4jddZSB09cxY+g1RIb4ubs0EREREZFi49RzV+rjUj51bRjJFyPaEh7ow5+HUujzzlq2H052d1kiIiIiIsUm34/qeXh4EBoaesXwdOLECZcUVlT0qF7BxR/P4L5PfmdvUhoBPp68fWcLujaMdHdZIiIiIiIFUiSP6gFMnjyZ0NDQQhV3rjVr1vDqq6+yceNGEhISWLhwIX379r3sMatXr2bs2LFs376dKlWq8OSTTzJy5EiX1SSXVi08gPkPtWfUZ5v4ee8xRny6gWd6NeS+DjXUGikiIiIiZZpTwenOO+8kIiLCZRdPT0+nWbNm3HvvvQwYMOCK+8fFxdGzZ09GjBjBnDlzWLt2LQ8//DCVK1fO1/FSeKH+3sy89xqe+2Y7X/wWz4v/t4O4Y2lM6t0IL424JyIiIiJlVL6DU1G0KPTo0YMePXrke//333+fatWqMXXqVAAaNGjAhg0beO211xScipG3pwcv92vM1ZUD+fd3O5mzPp79xzN4d1BLQvy83V2eiIiIiIjL5buJIJ9doYrUunXr6NatW5513bt3Z8OGDWRnZ1/0mKysLFJSUvK8pPAsFgv3d6zFB/e0wt/bk5/2HGPAe79w4ESGu0sTEREREXG5fAcnu93u0sf0CiIxMZHIyLyDEURGRpKTk8OxY8cuesyUKVMIDQ11vGJiYoqj1HKjW6MovhrZjsgQX/YkpdHvvbVsij/p7rJERERERFyq1HVKOf+RwTMtYZd6lHDixIkkJyc7XgcOHCjyGsubxleF8s2o62hUJYRjaVbunL6eb7cedndZIiIiIiIuU6qCU1RUFImJiXnWJSUl4eXlRXh4+EWP8fX1JSQkJM9LXC8q1I8vH2xH1wYRWHPsjPliM/9bsadEPOIpIiIiIlJYpSo4tWvXjuXLl+dZt2zZMlq3bo23twYlcLdAXy8+GNya4dfVBOD15bsZ9+VWsnJsbq5MRERERKRw3Bqc0tLS2LJlC1u2bAHM4ca3bNlCfHw8YD5mN2TIEMf+I0eOZP/+/YwdO5adO3fy8ccfM2PGDMaPH++O8uUiPD0sPHtLQ17q2xhPDwsLNh9i8Ee/cSLd6u7SREREREQKzK3BacOGDbRo0YIWLVoAMHbsWFq0aMFzzz0HQEJCgiNEAdSsWZPvvvuO2NhYmjdvzosvvsjbb7+tochLoHvaVmfmsGsI9vXit30n6P/eWo6lZbm7LBERERGRArEY5awTSkpKCqGhoSQnJ6u/UzHYfSSVe2f+zqFTmbS/OpxPh7fB08P1c4KJiIiIiDjLmWxQqvo4SelTNzKYmfdeg7+3J7/8fZzXl+1yd0kiIiIiIk5TcJIiVzcymP/c1hSA92L/Ztn2xCscISIiIiJSsig4SbG4tVkVhrWvAcC4r7ay71i6ewsSEREREXGCgpMUm6d6NqBltQqkns5h5JyNZFo1TLmIiIiIlA4KTlJsfLw8eG9QKyoF+fBXYipPL9qmCXJFREREpFRQcJJiFRXqx9t3tcDDAgs2HeLz3+KvfJCIiIiIiJspOEmxa391JZ7oXh+AyYt3sPXAKfcWJCIiIiJyBQpO4hYjr69Ft4aRWG12Hv5sEyfSre4uSURERETkkhScxC0sFguv3dGMGuEBHDqVyaNzN2Ozq7+TiIiIiJRMCk7iNiF+3ky7pxV+3h78tOcYb/24290liYiIiIhclIKTuFWD6BCm9G8CwNsr97LyryNurkhERERE5EIKTuJ2/VpU5Z621QB4fN5WDpzIcHNFIiIiIiJ5KThJifDsLQ1pFlOB5MxsRs7ZyOlsTY4rIiIiIiWHgpOUCL5enkwb1JKwAG+2H07h+W+2u7skEREREREHBScpMapU8Oftu1pgscC8DQeY97smxxURERGRkkHBSUqUjnUqM+6mugA8+812/jyU7OaKREREREQUnKQEerhzbbrUj8CaY2fknI2cytDkuCIiIiLiXgpOUuJ4eFh4447mVKsYwMGTmTw+bwt2TY4rIiIiIm6k4CQlUmiAN9PuaYmvlwerdh3l3VV73V2SiIiIiJRjCk5SYjWqEsqLfRsD8MaPu/lpz1E3VyQiIiIi5ZWCk5Rod7SO4c5rYjAMeHTuFg6fynR3SSIiIiJSDik4SYk36dZGNKoSwol0Kw9/tglrjt3dJYmIiIhIOaPgJCWen7cn0wa1IsTPiy0HTvHvJTvcXZKIiIiIlDMKTlIqVAsP4M2BzQH4ZN1+vtlyyL0FiYiIiEi5ouAkpUaXBpGMvqE2AP+av43dR1LdXJGIiIiIlBcKTlKqPH5TXTrUDicz28bIORtJy8pxd0kiIiIiUg4oOEmp4ulh4a07WxAV4sc/R9OZ8PUfGIYmxxURERGRoqXgJKVOpSBf3h3UEi8PC0u2JfDx2n3uLklEREREyjgFJymVWlUP45leDQCY8t1ONuw74eaKRERERKQsU3CSUmto+xr0blaFHLvBqM83cTQ1y90liYiIiEgZpeAkpZbFYuGV/k2oHRHEkZQsHvliMzk2TY4rIiIiIq6n4CSlWqCvF+/f05IAH0/W/XOc15fvdndJIiIiIlIGKThJqVc7Ipj/DGgKwLTYv1m+44ibKxIRERGRssbtwem9996jZs2a+Pn50apVK3766adL7hsbG4vFYrng9ddffxVjxVIS9W5WhWHtawAw9sst7D+e7t6CRERERKRMcWtwmjdvHo899hhPP/00mzdvpmPHjvTo0YP4+PjLHrdr1y4SEhIcrzp16hRTxVKSPdWzAS2rVSD1dA4j52zidLbN3SWJiIiISBnh1uD0xhtvMHz4cO6//34aNGjA1KlTiYmJYdq0aZc9LiIigqioKMfL09OzmCqWkszHy4N3B7UkPNCHnQkpPLVgG3a7JscVERERkcJzW3CyWq1s3LiRbt265VnfrVs3fvnll8se26JFC6Kjo+nSpQurVq267L5ZWVmkpKTkeUnZFR3qz9t3tcDDAgs2H+LpRQpPIiIiIlJ4bgtOx44dw2azERkZmWd9ZGQkiYmJFz0mOjqa6dOnM3/+fBYsWEC9evXo0qULa9asueR1pkyZQmhoqOMVExPj0u8hJU+H2pV4/Y5meFjgi98OMFEtTyIiIiJSSF7uLsBiseRZNgzjgnVn1KtXj3r16jmW27Vrx4EDB3jttdfo1KnTRY+ZOHEiY8eOdSynpKQoPJUD/VpUxcNi4fF5W5i34QA2w+A/A5ri6XHxe0tERERE5HLc1uJUqVIlPD09L2hdSkpKuqAV6nLatm3Lnj17Lrnd19eXkJCQPC8pH/o0v4qpd5qP7X298SBPfL0Vm1qeRERERKQA3BacfHx8aNWqFcuXL8+zfvny5bRv3z7f59m8eTPR0dGuLk/KiFubVeHtu1rg6WFhwaZDjP9K4UlEREREnOfWR/XGjh3L4MGDad26Ne3atWP69OnEx8czcuRIwHzM7tChQ8yePRuAqVOnUqNGDRo1aoTVamXOnDnMnz+f+fPnu/NrSAl3S9MqeFgsPPLFZhZuPoTdMHj99mZ4ebp9GjMRERERKSXcGpwGDhzI8ePHeeGFF0hISKBx48Z89913VK9eHYCEhIQ8czpZrVbGjx/PoUOH8Pf3p1GjRixZsoSePXu66ytIKdGzSTQeFhj9+Wa+2XIYuwFv3qHwJCIiIiL5YzEMo1w9t5SSkkJoaCjJycnq71QO/bA9kdGfbyLbZtCraTRTBzbHW+FJREREpFxyJhvoJ0YpV7o3imLaoFZ4e1pY8kcCj3yxmWyb3d1liYiIiEgJp+Ak5U7XhpG8f08rfDw9+P5PswXKmqPwJCIiIiKXpuAk5VKXBpF8MLgVPl4e/LD9CKMUnkRERETkMhScpNy6oX4EHw5pjY+XB8t3HOHhzzaSlWNzd1kiIiIiUgIpOEm5dn3dynw0pDW+Xh78uDOJh+ZsUngSERERkQsoOEm516luZWYMvQY/bw9W/pXEg59uJDkz291liYiIiEgJouAkAlxXpxIf54an2F1H6fJ6LPM3HqScjdYvIiIiIpeg4CSSq33tSnx2f1uurhzIsTQr477ayh0frGNnQoq7SxMRERERN1NwEjlHq+phfP9oJ/7Voz4BPp78vu8kt/zvZyZ/u52U03p8T0RERKS8UnASOY+Plwcjr7+aH8deT68m0djsBjPX7uPG11azcLMe3xMREREpjyxGOfspMCUlhdDQUJKTkwkJCXF3OVIK/LTnKM9/s51/jqUDcG3NirzYpzH1ooLdXJmIiIiIFIYz2UDBSSQfsnJsfPRTHP9buYfT2XY8PSwMa1+Dx7rWIdjP293liYiIiEgBOJMN9KieSD74enky6obarBjXmZsbRWGzG8z4OY4ur6/mmy2H9PieiIiISBmn4CTihKsq+PP+4FbMuvcaaoQHkJSaxaNzt3DXh+vZfSTV3eWJiIiISBFRcBIpgM71Ilj6WCfG3VQXXy8P1v9zgp5v/cSU73eSabW5uzwRERERcTEFJ5EC8vP2ZEyXOvw49npuahhJjt3gg9X/0H3qGn7ac9Td5YmIiIiICyk4iRRSTMUAPhzSmg+HtCY61I/4ExkMnvEbY+dt4US61d3liYiIiIgLKDiJuMhNDSNZ9ngnhrWvgcUCCzYfosvrsSzYpLmfREREREo7BScRFwr282bSrY1Y8FB76kcFczIjm7FfbmXwjN/Yfzzd3eWJiIiISAEpOIkUgRbVwvh2zHU8eXM9fL08+HnvMbpPXcP7q/8m22Z3d3kiIiIi4iQFJ5Ei4u3pwcOda/PDY53oUDuc09l2Xvn+L259Zy1bD5xyd3kiIiIi4gQFJ5EiVqNSIHOGt+G125tRIcCbnQkp9HtvLZO/3U56Vo67yxMRERGRfFBwEikGFouF21pVZcXY6+nX4irsBsxcu49ub65h5V9H3F2eiIiIiFyBxShnw32lpKQQGhpKcnIyISEh7i5Hyqk1u4/y9KJtHDiRCUDnepXp0TiK6+tGEBXq5+bqRERERMoHZ7KBgpOIm2RYc3jrxz189HMcNvvZ/wzrRwVzfb3KdK4bQesaYXh7qmFYREREpCgoOF2GgpOUNHuTUvm/PxKI3XWUrQdPce5/kUG+XnSoHU7nehFcX7cyVSr4u69QERERkTJGwekyFJykJDuZbmXNnqOs3nWU1buPcjzdmmd73cggOteLoHPdyrSuUREfL7VGiYiIiBSUgtNlKDhJaWG3G/x5OJnYXUeJ3ZXElgOnOOeJPgJ9PGl3dSWurRlGy2phNL4qFD9vT/cVLIWSbbOTnpVDWu4rPSuH1NM5pGfZSMvKJi3LRtrpHNKtZ9af3S/Ax5OoUD8iQ/yICvEjMjT3PcSPsABvLBaLu7+eiIhIiaTgdBkKTlJancqw8tOeY8TmtkYdS8vKs93b00KjKqG0rBZGy+oVaFktTI/2uZHNbnAqw8rxdCvH06wcT88y39OyOJZuvpvrrRxLyyL1dNEMTe/j5UFkiK8jSJ15jwz1o3KQL8F+XgT5ehGU++7r5aGgJSIi5YaC02UoOElZYLcb7EhI4ee9x9i0/ySb4k9dEKQAokP9aFktjBbVKtCyehiNqoTg66VWKVex2Q32HU9nZ0IKfyWksjMhhYMnMzmensWJdGueFsL88vXycASZQJ+zgSbI14tAXy+Cc9cH+noS7OdFgI8XaVk5JCaf5kiK+UpMyeJIymlOnPeoZ354eVjyXPNMsAo877O/tye+Xh74nnn3OrPsgd9F1p35HODjqWAmIiIlhoLTZSg4SVlkGAYHT2ayKf4kG/efZFP8SXYmpOYZrQ/M1ocmV4XSsloFKgb6YjcMbHbzZTeM3GUuWH/uu4+XB1Uq+FM1LICrKvhTNcyfykG+eHiU7R+GU09n81eiGY52JqSwIyGV3YmpZGbbLntchQBvwgN9CA/ypVKQD+GBvoQH5S4H+lAxd1vFQB+C/bxcOopiVo6NpNwQlZhy2hGuzgSrY2lZpGedeRyweCZjDvDxpFblQGpXDuLqykHUjgji6oggaoQHurzP3plWv1B/b7w0OqWIiFyEgtNlKDhJeZFhzWHrgWQ2xZ9kc7zZKlWQFoj88PH0ILqCH1dV8DdfYWffq1YIILqCX55AkJVjIz3LlqefTlruD/AXrLPmYDfMa/h4eeDtacE797OPp4fjs7enuc3X8dkDL08LnhYLFosFDwuOdw+LBct57x6OfcBuwD9H09iZ24q0MzHFMefW+fy8PagXGUyD6BAaRIdQq3IglYLMcBQW4FNqhpO32w3Srbl9rE7nkHrm7yD3c9rpc/peZeWQlW3ndI6NrGw7WTk2snLs5ivblvc9x9yebbv8/2o8PSxUqxjA1ZWDuDoiN1hFmOEq1N/bsZ9hGKRm5XA0NSvvK+3s56Tc9xPpWY575+qIIOpHBVM3Mth8jwqmSqifW1u/DMMgM9vGqYxsTmZYSc7IJstmBwMMDAwD85W7r/kOnNnGme0Gfl6e1KwcSPWKAQqJLpCWlcPepDTiT2RgwWyJ9fSwmP+meHjg5WExX+csezrWmcvenh55Wlw9y/gvl0Qu5XS2jePpVk7kPrZ+It3KiXQrx9KsDL+uJpWDfd1an4LTZSg4SXllGAb7jmewaf9Jth48RXqWDU8P8wdWD4slz/uZzx4WLlifabVx6FQmh05mcuhUJgnJmVd8JM1igUpBvo4BEK70Q3RJFRXiR4PosyGpQXQINSsF6geifLDZDbJybBw+dZq/j6axNymNv4+m8XdSGn8fTb9si1flYF+iQ/04kW7laGoWWTl2l9QU7OtF3ahg6kUF5wlVFQJ88n0Oa46dTKuNdGsOGVYbmVaz9S4505obiLI5lWnlVLr5fjIjm+TcoHQqMxuri77LGd6eFmqEBzpa82rnhs+rIwIJ8PFy6bXKguSMbPYeTWXPkTT2JJmvvUdSOZx82uXX8vSw5D7Cmvvoqrf52efcx1q9PAjw8aJysG+eV0Tue3igb5H+e2MYBlm593Rmto0Mq43Tue+Z2TYyrTmO9ZlWG1abHT8vTwJ8PPH38cTf25MAHy/8fTzw9/YiwMfc5ufjSYC3p0J9KZZts5NhtZFhNX/Jee77yYxsTqSf7bd7Iv3MexYn0qykWy/9ZMaCh9vTslpYMX6TC5Wq4PTee+/x6quvkpCQQKNGjZg6dSodO3a85P6rV69m7NixbN++nSpVqvDkk08ycuTIfF9PwUnEtXJsdhJTTjuClOM99/PBU5mX/OHQz9sjT/+dwHM+B/l65vbl8cLTw4I1x062zY7VZnd8zrYZWHPMddnnrLfmrs+22c3f1Bvm44cG5rvdbv6AYM9dbzfO/kbf3G5QNSwgNxwF0zA3JIUF5v8Hask/wzBISs1yhKlz34+kXNh3D8zQUznYl0pnfrgMyvuDZuUg84fNsEAfEk6dZteRVHYlprDrSBq7ElP452g6OZdI/BHBvtSLCiYi2I/MbDMQZWTZyMjOMd9zf3jIsNoueQ5neHtaCPX3oUKAN37eHlgwW0ItABYLFvMt9/3cZXOlBbOF5J+j6Zd9dLRKqB9XnxOmakcEUatyIBUDfMr8D7TH08z7a09SWu67GZaSUi9+f4EZ2GuGB+LlaSHHZpBjt2OzG+TYjQuWbXaDbJuBzW53bM+22V1yf5zLwwLhQbn3d0je9/Ag8/Hrc4PO6TOB55wQlOlYZ3cEoUzr2c8uLjkPH08P/LzNcOjtZcHbw8PxSzkvTwte57be5bbmeZ+37O/tQcVAX8JzH3WuGOTj+Bwe6Iu/T+nox3tuEDnzb0y6NYdMq/l3ZWA4npgwf4EJHuf+UvMS2+yG4XgSwOpo9T9v+YLtNk5nnxOMrDYysnLyLBf2lzzenhbz7+vcv7tAH4a2r0HNSoEu+lMtmFITnObNm8fgwYN577336NChAx988AEfffQRO3bsoFq1ahfsHxcXR+PGjRkxYgQPPvgga9eu5eGHH+aLL75gwIAB+bqmgpNI8TIMg2NpVo6knMbXy8MRkAJ99NtHubLU09n8fTSdo6lZVAz0ISLYl0pBhf/hyJpj559jaexKTGVXYiq7j6TyV2IqB09e/JHMK/H2tDh+2x7g60kFf2/CAnwIDTDfK/h7UyHQx7G+QoB37suHQBcNmGG3GySknGZvUt7w+XdS2gVzwp3P/CWGN0G+no6BSYL9zv4y49xfcJwZPMTfxxO/3JYTx3vuwCBn3gv7qOqZX3Dk2O3k2Izc1rxs85WRffZz7isl88J1yZnZl22lrBLqR+3IYOpEBJmvyCBqVw4mNMD7ksfkl81u5P5wasvzA+u5P8yeWW+1mY+4pp3zKGrSOe/H07Mozp/YfDw9zmlF8sTP+2zL0pnP3p4enM4+2yp1bgvV2c85RRrGzhfg45kbonzO/qCe++i0l4f5Swk4/5cQucsX/YWFBZthkGMz70Fr7nuO3fzlXU5uQM7O/QVejs0g226ut+bkDSOO1ukss7WuNPLysDj+Hx7ga7YqVgjwyROGHEE2yPzzrxjoQ4ifV4kdGKjUBKc2bdrQsmVLpk2b5ljXoEED+vbty5QpUy7Yf8KECSxevJidO3c61o0cOZKtW7eybt26fF1TwUlERC4lLSuH3UfMMHUqI5tAX888gSjg3M8+ngR4mwGipE9GfTLdekFr3t6jaRw8mVmkP4yfeTzt3EDl7WlxDD6Tc/67zX7BelewWKBqmD91IsyAVDsiiDqRwVxdOZBgv8IHpOKQY7NzIt3qCFNn+vYlpZzmaFoWx9KseHmYAf7Mo3Fngs+5744A5H2Rdeesd9Uvts48/nduoMq02sg+02KXG0Jy7AY2W26L3jnbbHYjz74Z1hzH42Ancqd7OPO5NIYRLw9L7iON5r8rgT7mqKVYzv7iwGY38nw+M5iT46kJ+9nPFgv4eXnmPgJqPgbq+OztiY+nh+Mx0Tzbcn+xGeBj1hDgeOrDrC3Qp3T8W1cQzmQDtz3wbLVa2bhxI//617/yrO/WrRu//PLLRY9Zt24d3bp1y7Oue/fuzJgxg+zsbLy9L/zHLysri6yss03xKSkpLqheRETKoiBfL3MuNDc/c+9qYYE+tA6sSOsaFfOst+bY8064fM4AIedOyHyxyZczrDbHD8Tnvp/7SI/Nbjh+WHYFDwuE+HsT6u9NBX9vx+dLvc5sd0Urpbt5eXoQEeJHRIifu0txisViwc/bDGcVAoruOoZhtkie28/mRHqWY1CCkxnZ5iPb5wy0cu7AKxcOynLmMW7w9DD//H1yB/7wyh2MyMvDw/HIoVfuwEVnBgY5M5BRQG7rjL/P2SDi75PbYuPjVSaDSFnmtuB07NgxbDYbkZGRedZHRkaSmJh40WMSExMvun9OTg7Hjh0jOjr6gmOmTJnC5MmTXVe4iIhIGeHj5UFFL/OxGlex283Hmc4PVOcGqzMj0JnvHuf0YbnIeg8Lnp7mu5+XZ5mf+kAKxmKxEOznTbCfNzXc3GdGyi63D7Fz/vOOhmFc9hnIi+1/sfVnTJw4kbFjxzqWU1JSiImJKWi5IiIichkeHhb8PMwWBhGRssRtwalSpUp4enpe0LqUlJR0QavSGVFRURfd38vLi/Dw8Ise4+vri6+ve8eHFxERERGR0s1tD1b6+PjQqlUrli9fnmf98uXLad++/UWPadeu3QX7L1u2jNatW1+0f5OIiIiIiIgruLVH2tixY/noo4/4+OOP2blzJ48//jjx8fGOeZkmTpzIkCFDHPuPHDmS/fv3M3bsWHbu3MnHH3/MjBkzGD9+vLu+goiIiIiIlANu7eM0cOBAjh8/zgsvvEBCQgKNGzfmu+++o3r16gAkJCQQHx/v2L9mzZp89913PP7447z77rtUqVKFt99+O99zOImIiIiIiBSEW+dxcgfN4yQiIiIiIuBcNtDg8SIiIiIiIleg4CQiIiIiInIFCk4iIiIiIiJXoOAkIiIiIiJyBQpOIiIiIiIiV6DgJCIiIiIicgUKTiIiIiIiIleg4CQiIiIiInIFCk4iIiIiIiJX4OXuAoqbYRiAOUuwiIiIiIiUX2cywZmMcDnlLjilpqYCEBMT4+ZKRERERESkJEhNTSU0NPSy+1iM/MSrMsRut3P48GGCg4OxWCwuOWdKSgoxMTEcOHCAkJAQl5xTyg/dP1IYun+kMHT/SEHp3pHCKEn3j2EYpKamUqVKFTw8Lt+Lqdy1OHl4eFC1atUiOXdISIjb//Kl9NL9I4Wh+0cKQ/ePFJTuHSmMknL/XKml6QwNDiEiIiIiInIFCk4iIiIiIiJXoODkAr6+vjz//PP4+vq6uxQphXT/SGHo/pHC0P0jBaV7RwqjtN4/5W5wCBEREREREWepxUlEREREROQKFJxERERERESuQMFJRERERETkChScRERERERErkDByQXee+89atasiZ+fH61ateKnn35yd0lSAq1Zs4bevXtTpUoVLBYLixYtyrPdMAwmTZpElSpV8Pf3p3Pnzmzfvt09xUqJMmXKFK655hqCg4OJiIigb9++7Nq1K88+un/kUqZNm0bTpk0dE022a9eO77//3rFd947k15QpU7BYLDz22GOOdbp/5FImTZqExWLJ84qKinJsL433joJTIc2bN4/HHnuMp59+ms2bN9OxY0d69OhBfHy8u0uTEiY9PZ1mzZrxzjvvXHT7f//7X9544w3eeecdfv/9d6KiorjppptITU0t5kqlpFm9ejWjRo1i/fr1LF++nJycHLp160Z6erpjH90/cilVq1bllVdeYcOGDWzYsIEbb7yRPn36OH5A0b0j+fH7778zffp0mjZtmme97h+5nEaNGpGQkOB4bdu2zbGtVN47hhTKtddea4wcOTLPuvr16xv/+te/3FSRlAaAsXDhQsey3W43oqKijFdeecWx7vTp00ZoaKjx/vvvu6FCKcmSkpIMwFi9erVhGLp/xHlhYWHGRx99pHtH8iU1NdWoU6eOsXz5cuP66683Hn30UcMw9G+PXN7zzz9vNGvW7KLbSuu9oxanQrBarWzcuJFu3brlWd+tWzd++eUXN1UlpVFcXByJiYl57iVfX1+uv/563UtygeTkZAAqVqwI6P6R/LPZbMydO5f09HTatWune0fyZdSoUfTq1YuuXbvmWa/7R65kz549VKlShZo1a3LnnXfyzz//AKX33vFydwGl2bFjx7DZbERGRuZZHxkZSWJiopuqktLozP1ysXtp//797ihJSijDMBg7dizXXXcdjRs3BnT/yJVt27aNdu3acfr0aYKCgli4cCENGzZ0/ICie0cuZe7cuWzcuJENGzZcsE3/9sjltGnThtmzZ1O3bl2OHDnCSy+9RPv27dm+fXupvXcUnFzAYrHkWTYM44J1Ivmhe0muZPTo0fzxxx/8/PPPF2zT/SOXUq9ePbZs2cKpU6eYP38+Q4cOZfXq1Y7tunfkYg4cOMCjjz7KsmXL8PPzu+R+un/kYnr06OH43KRJE9q1a8fVV1/NJ598Qtu2bYHSd+/oUb1CqFSpEp6enhe0LiUlJV2QoEUu58woM7qX5HLGjBnD4sWLWbVqFVWrVnWs1/0jV+Lj40Pt2rVp3bo1U6ZMoVmzZrz11lu6d+SyNm7cSFJSEq1atcLLywsvLy9Wr17N22+/jZeXl+Me0f0j+REYGEiTJk3Ys2dPqf23R8GpEHx8fGjVqhXLly/Ps3758uW0b9/eTVVJaVSzZk2ioqLy3EtWq5XVq1frXhIMw2D06NEsWLCAlStXUrNmzTzbdf+IswzDICsrS/eOXFaXLl3Ytm0bW7Zscbxat27NoEGD2LJlC7Vq1dL9I/mWlZXFzp07iY6OLrX/9uhRvUIaO3YsgwcPpnXr1rRr147p06cTHx/PyJEj3V2alDBpaWns3bvXsRwXF8eWLVuoWLEi1apV47HHHuPll1+mTp061KlTh5dffpmAgADuvvtuN1YtJcGoUaP4/PPP+eabbwgODnb8hi40NBR/f3/HvCq6f+RinnrqKXr06EFMTAypqanMnTuX2NhYli5dqntHLis4ONjRl/KMwMBAwsPDHet1/8iljB8/nt69e1OtWjWSkpJ46aWXSElJYejQoaX33x63jedXhrz77rtG9erVDR8fH6Nly5aOIYJFzrVq1SoDuOA1dOhQwzDMoTmff/55IyoqyvD19TU6depkbNu2zb1FS4lwsfsGMGbOnOnYR/ePXMp9993n+H9U5cqVjS5duhjLli1zbNe9I844dzhyw9D9I5c2cOBAIzo62vD29jaqVKli9O/f39i+fbtje2m8dyyGYRhuymwiIiIiIiKlgvo4iYiIiIiIXIGCk4iIiIiIyBUoOImIiIiIiFyBgpOIiIiIiMgVKDiJiIiIiIhcgYKTiIiIiIjIFSg4iYiIiIiIXIGCk4iIiBMsFguLFi1ydxkiIlLMFJxERKTUGDZsGBaL5YLXzTff7O7SRESkjPNydwEiIiLOuPnmm5k5c2aedb6+vm6qRkREygu1OImISKni6+tLVFRUnldYWBhgPkY3bdo0evTogb+/PzVr1uSrr77Kc/y2bdu48cYb8ff3Jzw8nAceeIC0tLQ8+3z88cc0atQIX19foqOjGT16dJ7tx44do1+/fgQEBFCnTh0WL15ctF9aRETcTsFJRETKlGeffZYBAwawdetW7rnnHu666y527twJQEZGBjfffDNhYWH8/vvvfPXVV/z44495gtG0adMYNWoUDzzwANu2bWPx4sXUrl07zzUmT57MHXfcwR9//EHPnj0ZNGgQJ06cKNbvKSIixctiGIbh7iJERETyY9iwYcyZMwc/P7886ydMmMCzzz6LxWJh5MiRTJs2zbGtbdu2tGzZkvfee48PP/yQCRMmcODAAQIDAwH47rvv6N27N4cPHyYyMpKrrrqKe++9l5deeumiNVgsFp555hlefPFFANLT0wkODua7775TXysRkTJMfZxERKRUueGGG/IEI4CKFSs6Prdr1y7Ptnbt2rFlyxYAdu7cSbNmzRyhCaBDhw7Y7XZ27dqFxWLh8OHDdOnS5bI1NG3a1PE5MDCQ4OBgkpKSCvqVRESkFFBwEhGRUiUwMPCCR+euxGKxAGAYhuPzxfbx9/fP1/m8vb0vONZutztVk4iIlC7q4yQiImXK+vXrL1iuX78+AA0bNmTLli2kp6c7tq9duxYPDw/q1q1LcHAwNWrUYMWKFcVas4iIlHxqcRIRkVIlKyuLxMTEPOu8vLyoVKkSAF999RWtW7fmuuuu47PPPuO3335jxowZAAwaNIjnn3+eoUOHMmnSJI4ePcqYMWMYPHgwkZGRAEyaNImRI0cSERFBjx49SE1NZe3atYwZM6Z4v6iIiJQoCk4iIlKqLF26lOjo6Dzr6tWrx19//QWYI97NnTuXhx9+mKioKD777DMaNmwIQEBAAD/88AOPPvoo11xzDQEBAQwYMIA33njDca6hQ4dy+vRp3nzzTcaPH0+lSpW47bbbiu8LiohIiaRR9UREpMywWCwsXLiQvn37ursU+f/27dgGAACEYdj/X3NCJpbK/iKCAoyxcQIAAAjCCQAAINg4ATDD9zkAX1ycAAAAgnACAAAIwgkAACAIJwAAgCCcAAAAgnACAAAIwgkAACAIJwAAgCCcAAAAwgELpcOaIhi3ugAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 정확도와 검증 정확도 그래프\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 훈련 정확도와 검증 정확도 그래프\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(range(1, num_epochs+1), val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Train and Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "coreerct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 59.33%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  for images, labels in test_dataloader:\n",
    "    images = images.float().to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "\n",
    "test_accuracy = 100 * correct / total \n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델의 복잡성을 늘려보았으나 오히려 정확도가 떨어짐  57퍼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "learning_rate = 0.001\n",
    "batch_size = 20\n",
    "num_epochs = 50\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로\n",
    "data_path = 'C:/Users/jungh/final_project/eye_deeplearning'\n",
    "classes = ['spring', 'summer', 'fall', 'winter']\n",
    "num_classes = len(classes)\n",
    "image_size = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, images, labels):\n",
    "    self.images = images\n",
    "    self.labels = labels\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    image = self.images[idx]\n",
    "    label = self.labels[idx]\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1 = nn.BatchNorm2d(32)\n",
    "    self.relu1 = nn.ReLU()\n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2 = nn.BatchNorm2d(64)\n",
    "    self.relu2 = nn.ReLU()\n",
    "    self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn3 = nn.BatchNorm2d(128)\n",
    "    self.relu3 = nn.ReLU()\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc1 = nn.Linear(128 * (image_size[0] // 8) * (image_size[1] // 8), 256)\n",
    "    self.bn4 = nn.BatchNorm1d(256)\n",
    "    self.relu4 = nn.ReLU()\n",
    "    self.fc2 = nn.Linear(256, num_classes)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = self.relu1(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bn2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.bn3(x)\n",
    "    x = self.relu3(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc1(x)\n",
    "    x = self.bn4(x)\n",
    "    x = self.relu4(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset():\n",
    "  x = []\n",
    "  y = []\n",
    "  \n",
    "  for i, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(data_path, class_name)\n",
    "    for image_name in os.listdir(class_path):\n",
    "      image_path = os.path.join(class_path, image_name)\n",
    "      image = cv2.imread(image_path)\n",
    "      image = cv2.resize(image, image_size)\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      x.append(image)\n",
    "      y.append(i)\n",
    "  \n",
    "  x = np.array(x)\n",
    "  y = np.array(y)\n",
    "  \n",
    "  return x, y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_dataset()\n",
    "# 데이터셋을 훈련 세트와 임시 데이터로 분할 (비율: 80% 훈련, 20% 임시 데이터)\n",
    "x_train_temp, x_test, y_train_temp, y_test = train_test_split(x, y, test_size = 0.2, random_state=SEED, stratify=y)\n",
    "\n",
    "# 임시 데이터를 다시 훈련 세트와 검증 세트로 분할 (비율: 75% 훈련, 25% 검증)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_temp, y_train_temp, test_size=0.25, random_state=SEED, stratify=y_train_temp)\n",
    "\n",
    "x_train = x_train.reshape(-1, 3, image_size[0], image_size[1])\n",
    "x_val = x_val.reshape(-1, 3, image_size[0], image_size[1])\n",
    "x_test = x_test.reshape(-1, 3, image_size[0], image_size[1])\n",
    "\n",
    "# 텐서로 변환\n",
    "x_train = torch.from_numpy(x_train).float() / 255.0\n",
    "x_val = torch.from_numpy(x_val).float() / 255.0\n",
    "x_test = torch.from_numpy(x_test).float() / 255.0\n",
    "\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_val = torch.LongTensor(y_val)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "val_dataset = CustomDataset(x_val, y_val)\n",
    "test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MyModel().float().to(device)\n",
    "model.conv1 = nn.Conv2d(x.shape[3], 32, kernel_size=3, stride=1, padding=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 76/76 [00:11<00:00,  6.90batch/s, loss=1.45] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: Train Loss: 1.4481, Val Accuracy: 25.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 76/76 [00:13<00:00,  5.69batch/s, loss=1.33] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: Train Loss: 1.3276, Val Accuracy: 27.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 76/76 [00:17<00:00,  4.40batch/s, loss=1.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: Train Loss: 1.2553, Val Accuracy: 26.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 76/76 [00:17<00:00,  4.46batch/s, loss=1.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: Train Loss: 1.1553, Val Accuracy: 24.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 76/76 [00:16<00:00,  4.63batch/s, loss=1.04] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: Train Loss: 1.0360, Val Accuracy: 29.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 76/76 [00:16<00:00,  4.48batch/s, loss=0.876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: Train Loss: 0.8762, Val Accuracy: 31.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 76/76 [00:19<00:00,  3.86batch/s, loss=0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: Train Loss: 0.6915, Val Accuracy: 28.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 76/76 [00:16<00:00,  4.68batch/s, loss=0.476] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: Train Loss: 0.4759, Val Accuracy: 29.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 76/76 [00:14<00:00,  5.11batch/s, loss=0.332] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: Train Loss: 0.3315, Val Accuracy: 32.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 76/76 [00:15<00:00,  4.79batch/s, loss=0.213] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: Train Loss: 0.2126, Val Accuracy: 30.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 76/76 [00:16<00:00,  4.66batch/s, loss=0.142] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: Train Loss: 0.1422, Val Accuracy: 30.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 76/76 [00:16<00:00,  4.50batch/s, loss=0.109] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: Train Loss: 0.1085, Val Accuracy: 30.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 76/76 [00:14<00:00,  5.19batch/s, loss=0.0877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: Train Loss: 0.0877, Val Accuracy: 31.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 76/76 [00:14<00:00,  5.22batch/s, loss=0.081] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: Train Loss: 0.0810, Val Accuracy: 29.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 76/76 [00:16<00:00,  4.67batch/s, loss=0.127]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: Train Loss: 0.1271, Val Accuracy: 31.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 76/76 [00:20<00:00,  3.75batch/s, loss=0.108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: Train Loss: 0.1076, Val Accuracy: 30.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 76/76 [00:15<00:00,  5.06batch/s, loss=0.0559] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: Train Loss: 0.0559, Val Accuracy: 30.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 76/76 [00:15<00:00,  4.96batch/s, loss=0.0521] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: Train Loss: 0.0521, Val Accuracy: 30.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 76/76 [00:20<00:00,  3.63batch/s, loss=0.0823] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: Train Loss: 0.0823, Val Accuracy: 31.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 76/76 [00:18<00:00,  4.16batch/s, loss=0.069] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: Train Loss: 0.0690, Val Accuracy: 30.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 76/76 [00:16<00:00,  4.55batch/s, loss=0.0574] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: Train Loss: 0.0574, Val Accuracy: 31.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 76/76 [00:20<00:00,  3.68batch/s, loss=0.0642] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: Train Loss: 0.0642, Val Accuracy: 32.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 76/76 [00:21<00:00,  3.46batch/s, loss=0.0657] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: Train Loss: 0.0657, Val Accuracy: 30.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 76/76 [00:15<00:00,  5.06batch/s, loss=0.0458] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: Train Loss: 0.0458, Val Accuracy: 32.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 76/76 [00:14<00:00,  5.27batch/s, loss=0.0324] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: Train Loss: 0.0324, Val Accuracy: 33.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 76/76 [00:15<00:00,  4.96batch/s, loss=0.0306] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: Train Loss: 0.0306, Val Accuracy: 31.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 76/76 [00:14<00:00,  5.09batch/s, loss=0.0375] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: Train Loss: 0.0375, Val Accuracy: 34.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 76/76 [00:16<00:00,  4.67batch/s, loss=0.0672] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: Train Loss: 0.0672, Val Accuracy: 30.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 76/76 [00:15<00:00,  4.92batch/s, loss=0.0625] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: Train Loss: 0.0625, Val Accuracy: 28.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 76/76 [00:14<00:00,  5.17batch/s, loss=0.0834] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: Train Loss: 0.0834, Val Accuracy: 30.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 76/76 [00:14<00:00,  5.11batch/s, loss=0.0596] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: Train Loss: 0.0596, Val Accuracy: 32.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 76/76 [00:15<00:00,  5.07batch/s, loss=0.0625] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: Train Loss: 0.0625, Val Accuracy: 27.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 76/76 [00:16<00:00,  4.61batch/s, loss=0.0544] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: Train Loss: 0.0544, Val Accuracy: 32.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 76/76 [00:16<00:00,  4.57batch/s, loss=0.0468] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: Train Loss: 0.0468, Val Accuracy: 33.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 76/76 [00:14<00:00,  5.09batch/s, loss=0.033]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: Train Loss: 0.0330, Val Accuracy: 30.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 76/76 [00:15<00:00,  4.81batch/s, loss=0.0218] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: Train Loss: 0.0218, Val Accuracy: 31.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 76/76 [00:14<00:00,  5.17batch/s, loss=0.0245]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: Train Loss: 0.0245, Val Accuracy: 33.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 76/76 [00:15<00:00,  4.94batch/s, loss=0.0154] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: Train Loss: 0.0154, Val Accuracy: 31.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 76/76 [00:16<00:00,  4.54batch/s, loss=0.0222] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: Train Loss: 0.0222, Val Accuracy: 28.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 76/76 [00:16<00:00,  4.63batch/s, loss=0.0277] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: Train Loss: 0.0277, Val Accuracy: 31.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 76/76 [00:14<00:00,  5.16batch/s, loss=0.0697] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: Train Loss: 0.0697, Val Accuracy: 33.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 76/76 [00:15<00:00,  5.04batch/s, loss=0.054]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: Train Loss: 0.0540, Val Accuracy: 31.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 76/76 [00:16<00:00,  4.71batch/s, loss=0.0558] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: Train Loss: 0.0558, Val Accuracy: 29.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 76/76 [00:15<00:00,  5.05batch/s, loss=0.047]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: Train Loss: 0.0470, Val Accuracy: 32.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 76/76 [00:14<00:00,  5.17batch/s, loss=0.0445] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: Train Loss: 0.0445, Val Accuracy: 31.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 76/76 [00:14<00:00,  5.27batch/s, loss=0.0567] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: Train Loss: 0.0567, Val Accuracy: 31.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 76/76 [00:16<00:00,  4.63batch/s, loss=0.0555] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: Train Loss: 0.0555, Val Accuracy: 30.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 76/76 [00:17<00:00,  4.37batch/s, loss=0.0536] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: Train Loss: 0.0536, Val Accuracy: 30.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 76/76 [00:15<00:00,  4.86batch/s, loss=0.0242] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: Train Loss: 0.0242, Val Accuracy: 30.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 76/76 [00:14<00:00,  5.25batch/s, loss=0.014]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: Train Loss: 0.0140, Val Accuracy: 29.82%\n"
     ]
    }
   ],
   "source": [
    "best_val_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  \n",
    "  \n",
    "  with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as progress_bar:\n",
    "    for images, labels in train_dataloader:\n",
    "      images = images.float().to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      running_loss += loss.item()\n",
    "      progress_bar.set_postfix(loss=running_loss / (len(train_dataloader)))\n",
    "      progress_bar.update()\n",
    "  \n",
    "  \n",
    "  epoch_loss = running_loss / len(train_dataloader)\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  \n",
    "  \n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for images, labels in val_dataloader:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "  val_accuracy = 100 * correct / total\n",
    "\n",
    "  print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {epoch_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# 검증 세트의 정확도가 이전에 기록한 최고 정확도보다 높으면 모델 저장\n",
    "  if val_accuracy > best_val_accuracy:\n",
    "      best_val_accuracy = val_accuracy\n",
    "      torch.save(model.state_dict(), 'best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "coreerct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 57.14%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  for images, labels in test_dataloader:\n",
    "    images = images.float().to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "\n",
    "test_accuracy = 100 * correct / total \n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전학습 모델 사용해보자 1.Efficientnetb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/jungh/final_project/eye_deeplearning'\n",
    "classes = ['spring', 'summer', 'fall', 'winter']\n",
    "num_classes = len(classes)\n",
    "image_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "  transforms.Resize((image_size, image_size)),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(data_path, transform=data_transform)\n",
    "\n",
    "x_train_temp, x_test, y_train_temp, y_test = train_test_split(dataset, dataset.targets, test_size = 0.2, random_state=SEED, stratify=y)\n",
    "# 임시 데이터를 다시 훈련 세트와 검증 세트로 분할 (비율: 75% 훈련, 25% 검증)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_temp, y_train_temp, test_size=0.25, random_state=SEED, stratify=y_train_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(x_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(x_val, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(x_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth\" to C:\\Users\\jungh/.cache\\torch\\hub\\checkpoints\\efficientnet-b1-f1951068.pth\n",
      "100%|██████████| 30.1M/30.1M [00:01<00:00, 21.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = EfficientNet.from_pretrained('efficientnet-b1', num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 48/48 [01:30<00:00,  1.88s/batch, Train Loss=42.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 2036.4184, Val Accuracy: 25.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 48/48 [01:25<00:00,  1.79s/batch, Train Loss=19.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Train Loss: 1882.9292, Val Accuracy: 24.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 48/48 [01:31<00:00,  1.90s/batch, Train Loss=11.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Train Loss: 1597.3561, Val Accuracy: 26.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 48/48 [01:30<00:00,  1.89s/batch, Train Loss=7.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Train Loss: 1478.2194, Val Accuracy: 25.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 48/48 [01:45<00:00,  2.21s/batch, Train Loss=5.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 1309.8488, Val Accuracy: 28.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 48/48 [01:56<00:00,  2.43s/batch, Train Loss=3.88] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Train Loss: 1118.8451, Val Accuracy: 26.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 48/48 [01:30<00:00,  1.89s/batch, Train Loss=2.81] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Train Loss: 945.2040, Val Accuracy: 32.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 48/48 [01:33<00:00,  1.94s/batch, Train Loss=1.89] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 724.2051, Val Accuracy: 27.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 48/48 [01:33<00:00,  1.96s/batch, Train Loss=1.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 678.3469, Val Accuracy: 29.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 48/48 [01:29<00:00,  1.87s/batch, Train Loss=1.18] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 564.2305, Val Accuracy: 28.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 48/48 [01:42<00:00,  2.14s/batch, Train Loss=0.871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Train Loss: 459.7418, Val Accuracy: 30.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 48/48 [01:57<00:00,  2.46s/batch, Train Loss=0.849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 489.2808, Val Accuracy: 30.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 48/48 [01:50<00:00,  2.31s/batch, Train Loss=0.757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Train Loss: 472.2052, Val Accuracy: 27.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 48/48 [01:55<00:00,  2.42s/batch, Train Loss=0.607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Train Loss: 407.8461, Val Accuracy: 28.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 48/48 [01:54<00:00,  2.39s/batch, Train Loss=0.368] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 264.6701, Val Accuracy: 30.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 48/48 [01:45<00:00,  2.19s/batch, Train Loss=0.518] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Train Loss: 398.0467, Val Accuracy: 30.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 48/48 [01:30<00:00,  1.88s/batch, Train Loss=0.522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Train Loss: 425.6425, Val Accuracy: 31.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 48/48 [01:31<00:00,  1.90s/batch, Train Loss=0.377] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Train Loss: 325.8376, Val Accuracy: 28.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 48/48 [01:45<00:00,  2.19s/batch, Train Loss=0.301] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Train Loss: 274.3581, Val Accuracy: 27.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 48/48 [01:55<00:00,  2.40s/batch, Train Loss=0.217] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Train Loss: 208.2889, Val Accuracy: 31.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 48/48 [01:30<00:00,  1.88s/batch, Train Loss=0.243]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Train Loss: 245.1654, Val Accuracy: 28.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 48/48 [01:26<00:00,  1.81s/batch, Train Loss=0.311] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Train Loss: 328.4104, Val Accuracy: 28.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 48/48 [01:27<00:00,  1.83s/batch, Train Loss=0.175]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Train Loss: 193.5616, Val Accuracy: 29.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 48/48 [01:27<00:00,  1.83s/batch, Train Loss=0.212] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Train Loss: 244.4112, Val Accuracy: 30.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 48/48 [01:26<00:00,  1.81s/batch, Train Loss=0.201] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Train Loss: 241.6184, Val Accuracy: 31.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 48/48 [01:27<00:00,  1.83s/batch, Train Loss=0.18]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Train Loss: 224.7944, Val Accuracy: 31.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 48/48 [01:27<00:00,  1.83s/batch, Train Loss=0.125] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Train Loss: 161.9287, Val Accuracy: 29.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 48/48 [01:26<00:00,  1.79s/batch, Train Loss=0.175] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Train Loss: 235.1431, Val Accuracy: 29.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 48/48 [01:28<00:00,  1.85s/batch, Train Loss=0.342] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Train Loss: 475.8582, Val Accuracy: 29.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 48/48 [01:30<00:00,  1.89s/batch, Train Loss=0.137] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Train Loss: 196.6608, Val Accuracy: 32.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 48/48 [01:25<00:00,  1.78s/batch, Train Loss=0.11]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Train Loss: 164.0270, Val Accuracy: 31.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 48/48 [01:26<00:00,  1.79s/batch, Train Loss=0.0901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Train Loss: 138.4294, Val Accuracy: 28.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 48/48 [01:28<00:00,  1.83s/batch, Train Loss=0.0804] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Train Loss: 127.3973, Val Accuracy: 30.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 48/48 [01:25<00:00,  1.79s/batch, Train Loss=0.0747] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Train Loss: 121.9532, Val Accuracy: 29.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 48/48 [01:25<00:00,  1.78s/batch, Train Loss=0.0659] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Train Loss: 110.7923, Val Accuracy: 29.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 48/48 [01:28<00:00,  1.85s/batch, Train Loss=0.082] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Train Loss: 141.6277, Val Accuracy: 28.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 48/48 [01:23<00:00,  1.73s/batch, Train Loss=0.0792] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Train Loss: 140.7355, Val Accuracy: 31.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 48/48 [01:25<00:00,  1.78s/batch, Train Loss=0.111]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Train Loss: 203.1894, Val Accuracy: 28.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 48/48 [01:27<00:00,  1.82s/batch, Train Loss=0.0892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Train Loss: 167.0469, Val Accuracy: 31.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 48/48 [01:27<00:00,  1.82s/batch, Train Loss=0.116] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Train Loss: 222.9249, Val Accuracy: 29.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 48/48 [01:23<00:00,  1.74s/batch, Train Loss=0.145] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Train Loss: 284.6848, Val Accuracy: 26.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 48/48 [01:26<00:00,  1.80s/batch, Train Loss=0.0562] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Train Loss: 113.3885, Val Accuracy: 27.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 48/48 [01:31<00:00,  1.92s/batch, Train Loss=0.0533] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Train Loss: 110.0793, Val Accuracy: 31.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 48/48 [01:26<00:00,  1.81s/batch, Train Loss=0.073] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Train Loss: 154.1140, Val Accuracy: 30.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 48/48 [01:25<00:00,  1.78s/batch, Train Loss=0.0941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Train Loss: 203.3106, Val Accuracy: 28.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 48/48 [01:29<00:00,  1.87s/batch, Train Loss=0.0818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Train Loss: 180.5330, Val Accuracy: 27.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 48/48 [01:26<00:00,  1.80s/batch, Train Loss=0.0675] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Train Loss: 152.2901, Val Accuracy: 28.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 48/48 [01:26<00:00,  1.81s/batch, Train Loss=0.0498] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Train Loss: 114.7556, Val Accuracy: 29.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 48/48 [01:31<00:00,  1.91s/batch, Train Loss=0.0378] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Train Loss: 88.9777, Val Accuracy: 28.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 48/48 [01:28<00:00,  1.85s/batch, Train Loss=0.0597] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Train Loss: 143.1893, Val Accuracy: 29.03%\n"
     ]
    }
   ],
   "source": [
    "best_val_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  train_loss = 0.0\n",
    "  \n",
    "  progress_bar = tqdm(total=len(train_loader),desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "  \n",
    "  for images, labels in train_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    progress_bar.set_postfix({'Train Loss': train_loss / ((epoch+1) * len(train_loader))})\n",
    "    progress_bar.update()\n",
    "  \n",
    "  \n",
    "  progress_bar.close()\n",
    "  \n",
    "  model.eval()\n",
    "  val_correct = 0\n",
    "  val_total = 0\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      \n",
    "      outputs = model(images)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      \n",
    "      val_total += labels.size(0)\n",
    "      val_correct += (predicted == labels).sum().item()\n",
    "  \n",
    "  val_accuracy = 100.0 * val_correct / val_total\n",
    "  \n",
    "  print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')   \n",
    "  \n",
    "  # 검증 세트의 정확도가 이전에 기록한 최고 정확도보다 높으면 모델 저장\n",
    "  if val_accuracy > best_val_accuracy:\n",
    "    best_val_accuracy = val_accuracy\n",
    "    torch.save(model.state_dict(), 'best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 29.56%\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100.0 * test_correct / test_total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':0.001,\n",
    "    'BATCH_SIZE':100,\n",
    "    'SEED':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "  random.seed(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])  # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'C:/Users/jungh/final_project/eye_deeplearning/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_list = glob.glob(train_dir + '*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['img_path', 'label'])\n",
    "df['img_path'] = all_img_list\n",
    "df['label'] = df['img_path'].apply(lambda x: str(x).split('\\\\')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_temp, x_test, y_train_temp, y_test = train_test_split(df, df['label'], test_size = 0.2, random_state=CFG['SEED'], stratify=df['label'])\n",
    "\n",
    "# 임시 데이터를 다시 훈련 세트와 검증 세트로 분할 (비율: 75% 훈련, 25% 검증)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_temp, y_train_temp, test_size=0.25, random_state=CFG['SEED'], stratify=y_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "x_train['label'] = le.fit_transform(x_train.label)\n",
    "x_val['label'] = le.transform(x_val['label'])\n",
    "x_test['label'] = le.transform(x_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_path_list[index]\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "val_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train['img_path'].values, x_train['label'].values, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(x_val['img_path'].values, x_val['label'].values, val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "test_dataset = CustomDataset(x_test['img_path'].values, x_test['label'].values, train_transform)\n",
    "test_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet_B1_Weights.IMAGENET1K_V2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torchvision.models.EfficientNet_B1_Weights.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_b1(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.008695652173913044, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.017391304347826087, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.026086956521739136, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.034782608695652174, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05217391304347827, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06086956521739131, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06956521739130435, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0782608695652174, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09565217391304348, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10434782608695654, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11304347826086956, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12173913043478261, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1920, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1920, bias=False)\n",
       "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1920, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(80, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(CFG['SEED'])\n",
    "torch.cuda.manual_seed(CFG['SEED'])\n",
    "\n",
    "output_shape = 4\n",
    "\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(in_features=1280,\n",
    "                    out_features=output_shape,\n",
    "                    bias=True)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.008695652173913044, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.017391304347826087, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.026086956521739136, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.034782608695652174, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05217391304347827, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06086956521739131, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06956521739130435, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0782608695652174, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09565217391304348, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10434782608695654, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11304347826086956, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12173913043478261, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1920, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1920, bias=False)\n",
       "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1920, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(80, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)      # ADDED .type(torch.LongTensor)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val Weighted F1 Score : [{_val_score:.5f}]')\n",
    "       \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "            \n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "           \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)      # ADDED .type(torch.LongTensor)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='weighted')\n",
    "    \n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30968\\1418884051.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_val_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LEARNING_RATE\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'abs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    train_losses = []  # 훈련 손실 기록\n",
    "    val_losses = []    # 검증 손실 기록\n",
    "    val_accuracies = []  # 검증 정확도 기록\n",
    "    train_accuracies = []  # 훈련 정확도 기록\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            _, predicted_train = torch.max(output.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted_train == labels).sum().item()\n",
    "            \n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        train_losses.append(_train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        val_losses.append(_val_loss)\n",
    "        val_accuracies.append(_val_score)\n",
    "        \n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Train Accuracy : [{train_accuracy:.5f}] Val Loss : [{_val_loss:.5f}] Val Weighted F1 Score : [{_val_score:.5f}]')\n",
    "       \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "            \n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "           \n",
    "    return best_model, train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='weighted')\n",
    "    \n",
    "    return _val_loss, _val_score\n",
    "\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model, train_losses, val_losses, train_accuracies, val_accuracies = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
